{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "97b67657-66cd-4bbf-9f8e-8499b17555bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoConfig, BertConfig, BertTokenizer\n",
    "from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n",
    "from transformers.data.processors.squad import SquadResult, SquadV1Processor, SquadV2Processor, squad_convert_examples_to_features, SquadExample\n",
    "from transformers import squad_convert_examples_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a9c8f19-03be-483c-9ba0-7222f680d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "qas_id = 'u_1'\n",
    "title = 'bla'\n",
    "question = 'Hội nghị Lập pháp ở Pháp đã tồn tại hai phe đối lập nào?'\n",
    "answer = \"nhóm 'Gironde' ủng hộ chiến tranh với Áo và Phổ, và nhóm 'Montagne' hoặc 'Jacobin' phản chiến\"\n",
    "context = \"Trong tháng 8 năm 1791, Hoàng đế Áo và Quốc vương Phổ trong Tuyên ngôn Pillnitz đe doạ nước Pháp cách mạng về việc can thiệp vũ lực nhằm khôi phục chế độ quân chủ chuyên chế. Trong tháng 9 năm 1791, Quốc hội lập hiến buộc Quốc vương Louis XVI chấp thuận Hiến pháp Pháp 1791, theo đó biến Pháp từ quốc gia theo chế độ quân chủ chuyên chế thành chế độ quân chủ lập hiến. Trong Hội nghị Lập pháp mới thành lập (tháng 10 năm 1791), tình trạng thù định phát triển và sâu sắc giữa nhóm 'Gironde' ủng hộ chiến tranh với Áo và Phổ, và nhóm 'Montagne' hoặc 'Jacobin' phản chiến. Ngày 20 tháng 4 năm 1792, Hội nghị Lập pháp tuyên chiến với Áo.\"\n",
    "s_pos = 475 \n",
    "e_pos = 568\n",
    "test = InputSquad(question, answer, context, s_pos, e_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "84271c54-c3e7-4ca9-9113-97d65abd5fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Trong tháng 8 năm 1791, Hoàng đế Áo và Quốc vương Phổ trong Tuyên ngôn Pillnitz đe doạ nước Pháp cách mạng về việc can thiệp vũ lực nhằm khôi phục chế độ quân chủ chuyên chế. Trong tháng 9 năm 1791, Quốc hội lập hiến buộc Quốc vương Louis XVI chấp thuận Hiến pháp Pháp 1791, theo đó biến Pháp từ quốc gia theo chế độ quân chủ chuyên chế thành chế độ quân chủ lập hiến. Trong Hội nghị Lập pháp mới thành lập (tháng 10 năm 1791), tình trạng thù định phát triển và sâu sắc giữa nhóm 'Gironde' ủng hộ chiến tranh với Áo và Phổ, và nhóm 'Montagne' hoặc 'Jacobin' phản chiến. Ngày 20 tháng 4 năm 1792, Hội nghị Lập pháp tuyên chiến với Áo.\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2e159444-e0e1-47bc-a397-e8838affd2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL, do_lower_case=False)\n",
    "tokenizer = BertTokenizer.from_pretrained('NlpHUST/vibert4news-base-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d40393d8-326c-48a0-9617-6fbed2092b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(' Original: ', context)\n",
    "# print('Tokenized: ', tokenizer.tokenize(context))\n",
    "# print('Token IDs: ', tokenizer.convert_ids_to_tokens(tokenizer.encode(context)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9a949b46-95fa-4245-a9a6-ac65f1196395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_enc(qas_ids, questions, titles, contexts, answers, is_impossibles, s_poses, tokenizer, args):\n",
    "    datas = []\n",
    "    for i in range(len(qas_ids)):\n",
    "        data = SquadExample(qas_id=qas_ids[i], question_text=questions[i], context_text=contexts[i], title=titles[i], answer_text=answers[i], answers=[{'answer_start':s_poses[i],'text':answers[i]}], is_impossible=is_impossibles[i], start_position_character=s_poses[i])\n",
    "        datas.append(data)\n",
    "    \n",
    "    features = squad_convert_examples_to_features(\n",
    "        examples=[datas],\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length= args.max_seq_length,\n",
    "        doc_stride= args.doc_stride,\n",
    "        max_query_length= args.max_query_length,\n",
    "        is_training=True,\n",
    "    )\n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "#     all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n",
    "    all_start_pos =  torch.tensor([f.start_position for f in features], dtype=torch.long)\n",
    "    all_end_pos = torch.tensor([f.end_position for f in features], dtype=torch.long)\n",
    "    \n",
    "    train_enc = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_start_pos, all_end_pos)\n",
    "    return train_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6f1b589a-d377-47f1-b45f-522f1edf93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_enc(qas_ids, questions, titles, contexts, answers, is_impossibles, s_poses, tokenizer, args):\n",
    "    datas = []\n",
    "    for i in range(len(qas_ids)):\n",
    "        data = SquadExample(qas_id=qas_ids[i], question_text=questions[i], context_text=contexts[i], title=titles[i], answer_text=answers[i], answers=[{'answer_start':s_poses[i],'text':answers[i]}], is_impossible=is_impossibles[i], start_position_character=s_poses[i])\n",
    "        datas.append(data)\n",
    "    \n",
    "    features = squad_convert_examples_to_features(\n",
    "        examples=[datas],\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length= args.max_seq_length,\n",
    "        doc_stride= args.doc_stride,\n",
    "        max_query_length= args.max_query_length,\n",
    "        is_training=True,\n",
    "    )\n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "    all_example_index = torch.arange([f.example_index for f in features], dtype=torch.long)\n",
    "    \n",
    "    valid_enc = TensorDataset(all_input_ids, all_input_mask, all_segment_ids)\n",
    "    return datas, valid_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f3e2a-16dd-4f76-83dd-f2619548c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_enc(qas_ids, questions, titles, contexts, tokenizer, args):\n",
    "    datas = []\n",
    "    for i in range(len(qas_ids)):\n",
    "        data = SquadExample(qas_id=qas_ids[i], question_text=questions[i], context_text=contexts[i], title=titles[i], answer_text=\"\", answers=[{'answer_start':-1,'text':\"\"}], is_impossible=False, start_position_character=-1)\n",
    "        datas.append(data)\n",
    "    \n",
    "    features = squad_convert_examples_to_features(\n",
    "        examples=[datas],\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length= args.max_seq_length,\n",
    "        doc_stride= args.doc_stride,\n",
    "        max_query_length= args.max_query_length,\n",
    "        is_training=True,\n",
    "    )\n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "    all_example_index = torch.arange([f.example_index for f in features], dtype=torch.long)\n",
    "    \n",
    "    valid_enc = TensorDataset(all_input_ids, all_input_mask, all_segment_ids)\n",
    "    return datas, valid_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "48da98af-bb42-4cd4-94f9-8d52e763a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [SquadExample(qas_id=qas_id, question_text=question, context_text=context, title=title, answer_text=answer, answers=[{'answer_start':s_pos,'text':answer}],is_impossible=False, start_position_character=s_pos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6f214853-c070-4b39-9ccc-ece2dbd3baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 66.69it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 34952.53it/s]\n"
     ]
    }
   ],
   "source": [
    "features = squad_convert_examples_to_features(\n",
    "    examples=example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=100,\n",
    "    doc_stride=50,\n",
    "    max_query_length=128,\n",
    "    is_training=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6e52e60c-86ad-485c-94bc-325fa8b59cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{17: 0,\n",
       " 18: 1,\n",
       " 19: 2,\n",
       " 20: 3,\n",
       " 21: 4,\n",
       " 22: 4,\n",
       " 23: 5,\n",
       " 24: 6,\n",
       " 25: 7,\n",
       " 26: 8,\n",
       " 27: 9,\n",
       " 28: 10,\n",
       " 29: 11,\n",
       " 30: 12,\n",
       " 31: 13,\n",
       " 32: 14,\n",
       " 33: 15,\n",
       " 34: 15,\n",
       " 35: 15,\n",
       " 36: 16,\n",
       " 37: 17,\n",
       " 38: 18,\n",
       " 39: 19,\n",
       " 40: 20,\n",
       " 41: 21,\n",
       " 42: 22,\n",
       " 43: 23,\n",
       " 44: 24,\n",
       " 45: 25,\n",
       " 46: 26,\n",
       " 47: 27,\n",
       " 48: 28,\n",
       " 49: 29,\n",
       " 50: 30,\n",
       " 51: 31,\n",
       " 52: 32,\n",
       " 53: 33,\n",
       " 54: 34,\n",
       " 55: 35,\n",
       " 56: 36,\n",
       " 57: 36,\n",
       " 58: 37,\n",
       " 59: 38,\n",
       " 60: 39,\n",
       " 61: 40,\n",
       " 62: 41,\n",
       " 63: 41,\n",
       " 64: 42,\n",
       " 65: 43,\n",
       " 66: 44,\n",
       " 67: 45,\n",
       " 68: 46,\n",
       " 69: 47,\n",
       " 70: 48,\n",
       " 71: 49,\n",
       " 72: 50,\n",
       " 73: 51,\n",
       " 74: 52,\n",
       " 75: 53,\n",
       " 76: 54,\n",
       " 77: 55,\n",
       " 78: 56,\n",
       " 79: 56,\n",
       " 80: 57,\n",
       " 81: 58,\n",
       " 82: 59,\n",
       " 83: 60,\n",
       " 84: 61,\n",
       " 85: 62,\n",
       " 86: 63,\n",
       " 87: 64,\n",
       " 88: 65,\n",
       " 89: 66,\n",
       " 90: 67,\n",
       " 91: 68,\n",
       " 92: 69,\n",
       " 93: 70,\n",
       " 94: 71,\n",
       " 95: 72,\n",
       " 96: 73,\n",
       " 97: 74,\n",
       " 98: 75}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].token_to_orig_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9d8bd8cd-e3fe-49ae-9eda-71935d45a9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trong',\n",
       " 'tháng',\n",
       " '8',\n",
       " 'năm',\n",
       " '1791,',\n",
       " 'Hoàng',\n",
       " 'đế',\n",
       " 'Áo',\n",
       " 'và',\n",
       " 'Quốc',\n",
       " 'vương',\n",
       " 'Phổ',\n",
       " 'trong',\n",
       " 'Tuyên',\n",
       " 'ngôn',\n",
       " 'Pillnitz',\n",
       " 'đe',\n",
       " 'doạ',\n",
       " 'nước',\n",
       " 'Pháp',\n",
       " 'cách',\n",
       " 'mạng',\n",
       " 'về',\n",
       " 'việc',\n",
       " 'can',\n",
       " 'thiệp',\n",
       " 'vũ',\n",
       " 'lực',\n",
       " 'nhằm',\n",
       " 'khôi',\n",
       " 'phục',\n",
       " 'chế',\n",
       " 'độ',\n",
       " 'quân',\n",
       " 'chủ',\n",
       " 'chuyên',\n",
       " 'chế.',\n",
       " 'Trong',\n",
       " 'tháng',\n",
       " '9',\n",
       " 'năm',\n",
       " '1791,',\n",
       " 'Quốc',\n",
       " 'hội',\n",
       " 'lập',\n",
       " 'hiến',\n",
       " 'buộc',\n",
       " 'Quốc',\n",
       " 'vương',\n",
       " 'Louis',\n",
       " 'XVI',\n",
       " 'chấp',\n",
       " 'thuận',\n",
       " 'Hiến',\n",
       " 'pháp',\n",
       " 'Pháp',\n",
       " '1791,',\n",
       " 'theo',\n",
       " 'đó',\n",
       " 'biến',\n",
       " 'Pháp',\n",
       " 'từ',\n",
       " 'quốc',\n",
       " 'gia',\n",
       " 'theo',\n",
       " 'chế',\n",
       " 'độ',\n",
       " 'quân',\n",
       " 'chủ',\n",
       " 'chuyên',\n",
       " 'chế',\n",
       " 'thành',\n",
       " 'chế',\n",
       " 'độ',\n",
       " 'quân',\n",
       " 'chủ',\n",
       " 'lập',\n",
       " 'hiến.',\n",
       " 'Trong',\n",
       " 'Hội',\n",
       " 'nghị',\n",
       " 'Lập',\n",
       " 'pháp',\n",
       " 'mới',\n",
       " 'thành',\n",
       " 'lập',\n",
       " '(tháng',\n",
       " '10',\n",
       " 'năm',\n",
       " '1791),',\n",
       " 'tình',\n",
       " 'trạng',\n",
       " 'thù',\n",
       " 'định',\n",
       " 'phát',\n",
       " 'triển',\n",
       " 'và',\n",
       " 'sâu',\n",
       " 'sắc',\n",
       " 'giữa',\n",
       " 'nhóm',\n",
       " \"'Gironde'\",\n",
       " 'ủng',\n",
       " 'hộ',\n",
       " 'chiến',\n",
       " 'tranh',\n",
       " 'với',\n",
       " 'Áo',\n",
       " 'và',\n",
       " 'Phổ,',\n",
       " 'và',\n",
       " 'nhóm',\n",
       " \"'Montagne'\",\n",
       " 'hoặc',\n",
       " \"'Jacobin'\",\n",
       " 'phản',\n",
       " 'chiến.',\n",
       " 'Ngày',\n",
       " '20',\n",
       " 'tháng',\n",
       " '4',\n",
       " 'năm',\n",
       " '1792,',\n",
       " 'Hội',\n",
       " 'nghị',\n",
       " 'Lập',\n",
       " 'pháp',\n",
       " 'tuyên',\n",
       " 'chiến',\n",
       " 'với',\n",
       " 'Áo.']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[features[0].example_index].doc_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0599e9b-68e5-46a9-be93-1904a871d6db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
