{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "TIIuLCHakiKJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TIIuLCHakiKJ",
    "outputId": "3f93d452-b5d9-418a-d475-e8a716a6a596"
   },
   "outputs": [],
   "source": [
    "# !pip install -q transformers\n",
    "# !pip install -q tf-models-official==2.2.0\n",
    "# !pip install pyvi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tx8GoLbbkZ5o",
   "metadata": {
    "id": "tx8GoLbbkZ5o"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel, BertModel, BertPreTrainedModel, BertConfig, RobertaConfig, RobertaModel, BertTokenizer, BertModel, RobertaTokenizer\n",
    "from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from official import nlp\n",
    "import official.nlp.optimization\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, WeightedRandomSampler\n",
    "import logging\n",
    "from tqdm import tqdm, trange\n",
    "from pyvi.ViTokenizer import tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "FYHCusHJkZ5q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYHCusHJkZ5q",
    "outputId": "57771315-2708-4f45-9ce5-bceff9214318"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#Get the GPU device name\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "if device_name == '/device:GPU:0':\n",
    "  print('GPU: {}'.format(device_name))\n",
    "else:\n",
    "  raise SystemError('GPU not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pXCtl05UkZ5q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXCtl05UkZ5q",
    "outputId": "ff54de8b-f53f-443f-fe1d-d85a9ccb4468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s).\n",
      "We will use the GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "  torch.cuda.set_device(0)\n",
    "  print('There are %d GPU(s).' % torch.cuda.device_count())\n",
    "  print('We will use the GPU:', torch.cuda.get_device_name())\n",
    "else:\n",
    "  print('No GPU, using CPU.')\n",
    "  device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "Bz5cI4H-kZ5r",
   "metadata": {
    "id": "Bz5cI4H-kZ5r"
   },
   "outputs": [],
   "source": [
    "base_dir    = '.'\n",
    "train_path  = os.path.join(base_dir, 'fix-train.csv')\n",
    "val_path    = os.path.join(base_dir, 'fix-val.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "XHEUng3PkZ5r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "XHEUng3PkZ5r",
    "outputId": "6f7cb7b1-1ac9-4c5a-b6aa-c81df63302fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25614, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25614 entries, 0 to 25613\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   title          25614 non-null  object\n",
      " 1   context        25614 non-null  object\n",
      " 2   answer_text    25614 non-null  object\n",
      " 3   answer_start   25614 non-null  int64 \n",
      " 4   id             25614 non-null  object\n",
      " 5   is_impossible  25614 non-null  bool  \n",
      " 6   question       25614 non-null  object\n",
      " 7   answer_end     25614 non-null  int64 \n",
      "dtypes: bool(1), int64(2), object(5)\n",
      "memory usage: 1.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>id</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pháp</td>\n",
       "      <td>Trong tháng 8 năm 1791, Hoàng đế Áo và Quốc vư...</td>\n",
       "      <td>nhóm 'Gironde' ủng hộ chiến tranh với Áo và Ph...</td>\n",
       "      <td>475</td>\n",
       "      <td>uit_024488</td>\n",
       "      <td>False</td>\n",
       "      <td>Hội nghị Lập pháp ở Pháp đã tồn tại hai phe đố...</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lịch sử Hoa Kỳ</td>\n",
       "      <td>Phe bảo hoàng mà người Anh trông cậy quá nhiều...</td>\n",
       "      <td>tháng 11 năm 1783</td>\n",
       "      <td>249</td>\n",
       "      <td>uit_017793</td>\n",
       "      <td>True</td>\n",
       "      <td>Đội quân cuối cùng của New Yord đã rời khỏi An...</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trung Hoa Dân Quốc (1912-1949)</td>\n",
       "      <td>Trong lĩnh vực toán học, Trung Hoa Dân Quốc đạ...</td>\n",
       "      <td>tiên phong và khai sáng vật lý học cận đại Tru...</td>\n",
       "      <td>177</td>\n",
       "      <td>uit_019463</td>\n",
       "      <td>False</td>\n",
       "      <td>Điều gì đã được làm bởi Ngô Hữu Huấn?</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iran</td>\n",
       "      <td>Iran là một thành viên sáng lập của Liên Hiệp ...</td>\n",
       "      <td>22 di sản</td>\n",
       "      <td>488</td>\n",
       "      <td>uit_022453</td>\n",
       "      <td>False</td>\n",
       "      <td>Có bao nhiêu di sản ở Iran được UNESCO công nhận?</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cách mạng Tháng Mười</td>\n",
       "      <td>Ngày 10-1-1918, Đại hội Xô viết toàn Nga lần t...</td>\n",
       "      <td>Xô viết đại biểu nông dân với Xô viết đại biểu...</td>\n",
       "      <td>98</td>\n",
       "      <td>uit_011191</td>\n",
       "      <td>True</td>\n",
       "      <td>Đại hội đã quyết định thành lập hai Xô viết đạ...</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title  \\\n",
       "0                            Pháp   \n",
       "1                  Lịch sử Hoa Kỳ   \n",
       "2  Trung Hoa Dân Quốc (1912-1949)   \n",
       "3                            Iran   \n",
       "4            Cách mạng Tháng Mười   \n",
       "\n",
       "                                             context  \\\n",
       "0  Trong tháng 8 năm 1791, Hoàng đế Áo và Quốc vư...   \n",
       "1  Phe bảo hoàng mà người Anh trông cậy quá nhiều...   \n",
       "2  Trong lĩnh vực toán học, Trung Hoa Dân Quốc đạ...   \n",
       "3  Iran là một thành viên sáng lập của Liên Hiệp ...   \n",
       "4  Ngày 10-1-1918, Đại hội Xô viết toàn Nga lần t...   \n",
       "\n",
       "                                         answer_text  answer_start  \\\n",
       "0  nhóm 'Gironde' ủng hộ chiến tranh với Áo và Ph...           475   \n",
       "1                                  tháng 11 năm 1783           249   \n",
       "2  tiên phong và khai sáng vật lý học cận đại Tru...           177   \n",
       "3                                          22 di sản           488   \n",
       "4  Xô viết đại biểu nông dân với Xô viết đại biểu...            98   \n",
       "\n",
       "           id  is_impossible  \\\n",
       "0  uit_024488          False   \n",
       "1  uit_017793           True   \n",
       "2  uit_019463          False   \n",
       "3  uit_022453          False   \n",
       "4  uit_011191           True   \n",
       "\n",
       "                                            question  answer_end  \n",
       "0  Hội nghị Lập pháp ở Pháp đã tồn tại hai phe đố...         568  \n",
       "1  Đội quân cuối cùng của New Yord đã rời khỏi An...         266  \n",
       "2              Điều gì đã được làm bởi Ngô Hữu Huấn?         230  \n",
       "3  Có bao nhiêu di sản ở Iran được UNESCO công nhận?         497  \n",
       "4  Đại hội đã quyết định thành lập hai Xô viết đạ...         167  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_path)\n",
    "print(df_train.shape)\n",
    "print(df_train.info())\n",
    "\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "GwI9YtepkZ5r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "GwI9YtepkZ5r",
    "outputId": "0cb22b5d-6501-4dd1-ef3a-8b3f7a31ccc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2846, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2846 entries, 0 to 2845\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   title          2846 non-null   object\n",
      " 1   context        2846 non-null   object\n",
      " 2   answer_text    2846 non-null   object\n",
      " 3   answer_start   2846 non-null   int64 \n",
      " 4   id             2846 non-null   object\n",
      " 5   is_impossible  2846 non-null   bool  \n",
      " 6   question       2846 non-null   object\n",
      " 7   answer_end     2846 non-null   int64 \n",
      "dtypes: bool(1), int64(2), object(5)\n",
      "memory usage: 158.5+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>id</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Một phần nhỏ tài sản của Trump nằm trong các k...</td>\n",
       "      <td>quyết định thâm nhập thị trường cổ phiếu</td>\n",
       "      <td>201</td>\n",
       "      <td>uit_015587</td>\n",
       "      <td>False</td>\n",
       "      <td>Hành động gì của Trump đã gây ra bất ngờ đối v...</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michael Jackson</td>\n",
       "      <td>Chuyến lưu diễn HIStory World Tour bắt đầu từ ...</td>\n",
       "      <td>82 đêm nhạc tại 58 thành phố, đi qua 5 châu lụ...</td>\n",
       "      <td>152</td>\n",
       "      <td>uit_008735</td>\n",
       "      <td>False</td>\n",
       "      <td>Chặng đường của HIStory World Tour như thế nào?</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bức tường Berlin</td>\n",
       "      <td>Công dân Đông Đức đã được người dân Tây Berlin...</td>\n",
       "      <td>tặng 100 DM khi qua cổng</td>\n",
       "      <td>458</td>\n",
       "      <td>uit_021854</td>\n",
       "      <td>False</td>\n",
       "      <td>Chính phủ chào đón người dân Đông Đức như thế ...</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nhà Minh</td>\n",
       "      <td>Sau khi Minh Thành Tổ lên ngôi, trong những nă...</td>\n",
       "      <td>triều đình nhận thấy tính quan trọng của mậu d...</td>\n",
       "      <td>1261</td>\n",
       "      <td>uit_018747</td>\n",
       "      <td>False</td>\n",
       "      <td>Vì sao triều đình lại từng bước xóa bỏ lệnh hả...</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Đế quốc La Mã</td>\n",
       "      <td>Cuộc chiến tranh Do Thái-La Mã lần thứ nhất, đ...</td>\n",
       "      <td>Cả hai cuộc khởi nghĩa này đều bị đàn áp dã man</td>\n",
       "      <td>800</td>\n",
       "      <td>uit_020519</td>\n",
       "      <td>False</td>\n",
       "      <td>Kết quả của hai cuộc khởi nghĩa của người Do T...</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title                                            context  \\\n",
       "0      Donald Trump  Một phần nhỏ tài sản của Trump nằm trong các k...   \n",
       "1   Michael Jackson  Chuyến lưu diễn HIStory World Tour bắt đầu từ ...   \n",
       "2  Bức tường Berlin  Công dân Đông Đức đã được người dân Tây Berlin...   \n",
       "3          Nhà Minh  Sau khi Minh Thành Tổ lên ngôi, trong những nă...   \n",
       "4     Đế quốc La Mã  Cuộc chiến tranh Do Thái-La Mã lần thứ nhất, đ...   \n",
       "\n",
       "                                         answer_text  answer_start  \\\n",
       "0           quyết định thâm nhập thị trường cổ phiếu           201   \n",
       "1  82 đêm nhạc tại 58 thành phố, đi qua 5 châu lụ...           152   \n",
       "2                           tặng 100 DM khi qua cổng           458   \n",
       "3  triều đình nhận thấy tính quan trọng của mậu d...          1261   \n",
       "4    Cả hai cuộc khởi nghĩa này đều bị đàn áp dã man           800   \n",
       "\n",
       "           id  is_impossible  \\\n",
       "0  uit_015587          False   \n",
       "1  uit_008735          False   \n",
       "2  uit_021854          False   \n",
       "3  uit_018747          False   \n",
       "4  uit_020519          False   \n",
       "\n",
       "                                            question  answer_end  \n",
       "0  Hành động gì của Trump đã gây ra bất ngờ đối v...         241  \n",
       "1    Chặng đường của HIStory World Tour như thế nào?         250  \n",
       "2  Chính phủ chào đón người dân Đông Đức như thế ...         482  \n",
       "3  Vì sao triều đình lại từng bước xóa bỏ lệnh hả...        1344  \n",
       "4  Kết quả của hai cuộc khởi nghĩa của người Do T...         847  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_val = pd.read_csv(val_path)\n",
    "print(df_val.shape)\n",
    "print(df_val.info())\n",
    "\n",
    "display(df_val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cdcda3e9-307e-40e1-a6c4-efd7a8df817f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                                                         Pháp\n",
       "context          Trong tháng 8 năm 1791, Hoàng đế Áo và Quốc vư...\n",
       "answer_text      nhóm 'Gironde' ủng hộ chiến tranh với Áo và Ph...\n",
       "answer_start                                                   475\n",
       "id                                                      uit_024488\n",
       "is_impossible                                                False\n",
       "question         Hội nghị Lập pháp ở Pháp đã tồn tại hai phe đố...\n",
       "answer_end                                                     568\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zhOIfWb9kZ5s",
   "metadata": {
    "id": "zhOIfWb9kZ5s"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "train_q  = df_train.question.values\n",
    "train_a  = df_train.answer_text.values\n",
    "train_c  = df_train.context.values\n",
    "train_ans_start = df_train.answer_start.values\n",
    "train_ans_end = df_train.answer_end.values\n",
    "\n",
    "val_q  = df_train.question.values\n",
    "val_a  = df_train.answer_text.values\n",
    "val_c  = df_train.context.values\n",
    "val_ans_start = df_train.answer_start.values\n",
    "val_ans_end = df_train.answer_end.values\n",
    "\n",
    "# test_sent    = df_val.tokenized.values\n",
    "# test_target = df_val.Target.values\n",
    "# test_stance_labels   = df_val.enc_label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oUMkYjNKkZ5s",
   "metadata": {
    "id": "oUMkYjNKkZ5s"
   },
   "outputs": [],
   "source": [
    "MODEL       = '/content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-810000'\n",
    "MAX_LENGTH    = 500\n",
    "MAX_LENGTH_Q  = 70\n",
    "# MAX_LENGTH_Q  = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gyaDBurukZ5s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gyaDBurukZ5s",
    "outputId": "083994a4-41f4-4acc-d77c-9b51e822cb60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL, do_lower_case=False)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ChVrrEyWkZ5t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChVrrEyWkZ5t",
    "outputId": "861c7e08-bc3e-4aeb-e048-d3a5e07e8207"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3308, 70]),\n",
       " torch.Size([3308, 70]),\n",
       " torch.Size([3308, 70]),\n",
       " torch.Size([3308, 500]),\n",
       " torch.Size([3308, 500]),\n",
       " torch.Size([3308, 500]),\n",
       " torch.Size([3308]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_1 = []\n",
    "attention_masks_1 = []\n",
    "token_type_ids_1 = []\n",
    "input_ids_2 = []\n",
    "attention_masks_2 = []\n",
    "token_type_ids_2 = []\n",
    "\n",
    "for sent1, sent2 in zip(train_sent_1, train_sent_2):\n",
    "  encoded_dict = tokenizer.encode_plus( sent1, \n",
    "                                        add_special_tokens = True, \n",
    "                                        max_length = MAX_LENGTH_Q,         \n",
    "                                        padding = 'max_length',\n",
    "                                        return_attention_mask = True,   \n",
    "                                        return_token_type_ids = True,   \n",
    "                                        truncation = True,\n",
    "                                  )\n",
    "  input_ids_1.append(encoded_dict['input_ids'])\n",
    "  attention_masks_1.append(encoded_dict['attention_mask'])\n",
    "  token_type_ids_1.append(encoded_dict['token_type_ids'])\n",
    "\n",
    "  encoded_dict = tokenizer.encode_plus( sent2, \n",
    "                                        add_special_tokens = True, \n",
    "                                        max_length = MAX_LENGTH,         \n",
    "                                        padding = 'max_length',\n",
    "                                        return_attention_mask = True,   \n",
    "                                        return_token_type_ids = True,   \n",
    "                                        truncation = True,\n",
    "                                  )\n",
    "  input_ids_2.append(encoded_dict['input_ids'])\n",
    "  attention_masks_2.append(encoded_dict['attention_mask'])\n",
    "  token_type_ids_2.append(encoded_dict['token_type_ids'])\n",
    "\n",
    "\n",
    "train_input_ids_1 = torch.tensor(input_ids_1)\n",
    "train_attention_masks_1 = torch.tensor(attention_masks_1)\n",
    "train_token_type_ids_1 = torch.tensor(token_type_ids_1)\n",
    "train_input_ids_2 = torch.tensor(input_ids_2)\n",
    "train_attention_masks_2 = torch.tensor(attention_masks_2)\n",
    "train_token_type_ids_2 = torch.tensor(token_type_ids_2)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_domains = torch.tensor(train_domains)\n",
    "train_input_ids_1.size(), train_attention_masks_1.size(), train_token_type_ids_1.size(), train_input_ids_2.size(), train_attention_masks_2.size(), train_token_type_ids_2.size(), train_labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kXRzXcfYkZ5t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXRzXcfYkZ5t",
    "outputId": "a6af8038-3411-4756-be52-150997f72e6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([832, 70]),\n",
       " torch.Size([832, 70]),\n",
       " torch.Size([832, 70]),\n",
       " torch.Size([832, 500]),\n",
       " torch.Size([832, 500]),\n",
       " torch.Size([832, 500]),\n",
       " torch.Size([832]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_1 = []\n",
    "attention_masks_1 = []\n",
    "token_type_ids_1 = []\n",
    "input_ids_2 = []\n",
    "attention_masks_2 = []\n",
    "token_type_ids_2 = []\n",
    "\n",
    "for sent1, sent2 in zip(val_sent_1, val_sent_2):\n",
    "  encoded_dict = tokenizer.encode_plus( sent1, \n",
    "                                        add_special_tokens = True, \n",
    "                                        max_length = MAX_LENGTH_Q,         \n",
    "                                        padding = 'max_length',\n",
    "                                        return_attention_mask = True,   \n",
    "                                        return_token_type_ids = True,   \n",
    "                                        truncation = True,\n",
    "                                  )\n",
    "  input_ids_1.append(encoded_dict['input_ids'])\n",
    "  attention_masks_1.append(encoded_dict['attention_mask'])\n",
    "  token_type_ids_1.append(encoded_dict['token_type_ids'])\n",
    "\n",
    "  encoded_dict = tokenizer.encode_plus( sent2, \n",
    "                                        add_special_tokens = True, \n",
    "                                        max_length = MAX_LENGTH,         \n",
    "                                        padding = 'max_length',\n",
    "                                        return_attention_mask = True,   \n",
    "                                        return_token_type_ids = True,   \n",
    "                                        truncation = True,\n",
    "                                  )\n",
    "  input_ids_2.append(encoded_dict['input_ids'])\n",
    "  attention_masks_2.append(encoded_dict['attention_mask'])\n",
    "  token_type_ids_2.append(encoded_dict['token_type_ids'])\n",
    "\n",
    "\n",
    "val_input_ids_1 = torch.tensor(input_ids_1)\n",
    "val_attention_masks_1 = torch.tensor(attention_masks_1)\n",
    "val_token_type_ids_1 = torch.tensor(token_type_ids_1)\n",
    "val_input_ids_2 = torch.tensor(input_ids_2)\n",
    "val_attention_masks_2 = torch.tensor(attention_masks_2)\n",
    "val_token_type_ids_2 = torch.tensor(token_type_ids_2)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "val_domains = torch.tensor(val_domains)\n",
    "val_input_ids_1.size(), val_attention_masks_1.size(), val_token_type_ids_1.size(), val_input_ids_2.size(), val_attention_masks_2.size(), val_token_type_ids_2.size(), val_labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j-TOGkenkZ5u",
   "metadata": {
    "id": "j-TOGkenkZ5u"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_input_ids_1, train_attention_masks_1, train_token_type_ids_1, train_input_ids_2, train_attention_masks_2, train_token_type_ids_2, train_labels, train_domains)\n",
    "val_data = TensorDataset(val_input_ids_1, val_attention_masks_1, val_token_type_ids_1, val_input_ids_2, val_attention_masks_2, val_token_type_ids_2, val_labels, val_domains)\n",
    "# test_data = TensorDataset(test_input_ids, test_attention_masks, test_token_type_ids, test_atheism, test_abortion, test_climate, test_feminist, test_stance_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Crga79jrkZ5u",
   "metadata": {
    "id": "Crga79jrkZ5u"
   },
   "outputs": [],
   "source": [
    "class ReverseLayer(Function):\n",
    "  @staticmethod\n",
    "  def forward(ctx, x, alpha):\n",
    "    ctx.alpha = alpha\n",
    "\n",
    "    return x.view_as(x) \n",
    "  \n",
    "  @staticmethod\n",
    "  def backward(ctx, grad_out):\n",
    "    output = grad_out.neg() * ctx.alpha\n",
    "    \n",
    "    return output, None\n",
    "\n",
    "class GRL(torch.nn.Module):\n",
    "    def __init__(self, lambda_=1):\n",
    "        super(GRL, self).__init__()\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def forward(self, x):\n",
    "        return ReverseLayer.apply(x, self.lambda_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dlXyl1dMkZ5u",
   "metadata": {
    "id": "dlXyl1dMkZ5u"
   },
   "outputs": [],
   "source": [
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.0, use_activation='None', set_bias=True):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.use_activation = use_activation\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear = nn.Linear(input_dim, output_dim, bias=set_bias)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.dropout_rate!=0.0:\n",
    "          temp = self.dropout(x)\n",
    "        else:\n",
    "          temp = x\n",
    "\n",
    "        if self.use_activation=='relu':\n",
    "            return self.relu(self.linear(temp))\n",
    "        if self.use_activation=='tanh':\n",
    "            return self.tanh(self.linear(temp))\n",
    "        if self.use_activation=='softmax':\n",
    "            return self.softmax(self.linear(temp))\n",
    "        if self.use_activation=='sigmoid':\n",
    "            return self.sigmoid(self.linear(temp))\n",
    "\n",
    "        return self.linear(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ljeijgu4kZ5v",
   "metadata": {
    "id": "Ljeijgu4kZ5v"
   },
   "outputs": [],
   "source": [
    "class CNN_Feature(nn.Module):\n",
    "  def __init__(self, hidden_size, debug=0):\n",
    "    super(CNN_Feature, self).__init__()\n",
    "\n",
    "    filter_sizes = [2,3,4,5]\n",
    "    batch_norm = []\n",
    "    self.conv_layers = nn.ModuleList()\n",
    "    self.size_pool = 5\n",
    "    for filter_size in filter_sizes:\n",
    "      self.conv_layers.append(\n",
    "          nn.Conv1d(\n",
    "              in_channels=hidden_size,\n",
    "              out_channels=hidden_size,\n",
    "              kernel_size=filter_size,\n",
    "          )\n",
    "      )\n",
    "\n",
    "    self.conv_layers_2 = nn.ModuleList()\n",
    "    for _ in range(2):\n",
    "      self.conv_layers_2.append(\n",
    "          nn.Conv1d(\n",
    "              in_channels=hidden_size,\n",
    "              out_channels=hidden_size,\n",
    "              kernel_size=self.size_pool,\n",
    "              padding='same'\n",
    "          )\n",
    "      )\n",
    "    self.linear_1 = FCLayer(6144, 768, use_activation='None')\n",
    "    self.linear_2 = FCLayer(768, 64, use_activation='None')\n",
    "    self.drop = nn.Dropout(0.2)\n",
    "    self.debug = debug\n",
    "    self.pool = nn.MaxPool1d(self.size_pool, stride=self.size_pool)\n",
    "  def forward(self, sent):\n",
    "    convs = []\n",
    "    drop_rate = 0.2\n",
    "    final_hid = 32\n",
    "\n",
    "    new_sent = sent.transpose(1,2) #Conv1d input\n",
    "    cnt = 1\n",
    "    for conv_layer in self.conv_layers:\n",
    "      cnt+=1\n",
    "      l_conv = conv_layer(new_sent)\n",
    "      # l_conv = l_conv.transpose(1,2).to(device)\n",
    "      batch_feature = l_conv.size(1)\n",
    "      if self.debug:\n",
    "        print('After conv with filter size {0}'.format(cnt),l_conv.size(), batch_feature)\n",
    "      # l_conv = self.batch_norm(l_conv)\n",
    "      l_conv = nn.ReLU()(l_conv)\n",
    "      # l_pool = MaxPooling1D(pool_size=max_len-filter_size+1)(l_conv)\n",
    "      l_pool = self.pool(l_conv)\n",
    "      if self.debug:\n",
    "        print('After pooling', l_pool.size())\n",
    "      convs.append(l_pool)\n",
    "      #merge.append(Flatten()(l_pool))\n",
    "\n",
    "    l2_pool = torch.cat(convs, dim=2)\n",
    "    if self.debug:\n",
    "      print('After cat', l2_pool.size())\n",
    "    # l2_pool = l2_pool.transpose(1,2)\n",
    "    # l2_pool = BatchNormalization()(l2_pool)\n",
    "    for conv_layer in self.conv_layers_2:\n",
    "      origin  = l2_pool\n",
    "      l2_conv = conv_layer(origin)\n",
    "      # l2_pool = l2_pool.transpose(1,2)\n",
    "      batch_feature = l2_conv.size(1)\n",
    "      # l2_conv = self.batch_norm(l2_conv)\n",
    "      l2_conv = nn.ReLU()(l2_conv)\n",
    "      if self.debug:\n",
    "        print(origin.shape, l2_conv.shape)\n",
    "      # l2_conv = Add()([Lambda(lambda x: x[0]*x[1])([origin,0.1]), l2_conv])\n",
    "      l2_conv = l2_conv+origin\n",
    "      l2_pool = self.pool(l2_conv)\n",
    "      if self.debug:\n",
    "        print('After pool', l2_pool.size())\n",
    "    if self.debug:\n",
    "      print('After second cnn', l2_pool.size())\n",
    "    text = l2_pool.view(l2_pool.size(0),-1)\n",
    "    if self.debug:\n",
    "      print(text.size())\n",
    "    #append to merge\n",
    "    \n",
    "    text_append = self.linear_1(text)\n",
    "    batch_feature = text_append.size(1)\n",
    "    # text_append = self.batch_norm(text_append)\n",
    "    text_append = self.drop(text_append)\n",
    "    text_append = nn.ReLU()(text_append)\n",
    "    text_append = self.linear_2(text_append)\n",
    "    batch_feature = text_append.size(1)\n",
    "    # text_append = nn.BatchNorm1d(batch_feature)(text_append)\n",
    "    text_append = nn.ReLU()(text_append)\n",
    "    return text_append\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rH__cUuokZ5v",
   "metadata": {
    "id": "rH__cUuokZ5v"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class CustomLSTM(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_sz, droprate=0.1):\n",
    "        super().__init__()\n",
    "        self.input_sz = input_sz\n",
    "        self.hidden_size = hidden_sz\n",
    "        self.W = nn.Parameter(torch.Tensor(input_sz, hidden_sz * 4))\n",
    "        self.U = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz * 4))\n",
    "        self.bias = nn.Parameter(torch.Tensor(hidden_sz * 4))\n",
    "        self.init_weights()\n",
    "        self.drop = nn.Dropout(droprate)\n",
    "    def init_weights(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "         \n",
    "    def forward(self, x, \n",
    "                init_states=None):\n",
    "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        if init_states is None:\n",
    "            h_t, c_t = (torch.zeros(bs, self.hidden_size).to(x.device), \n",
    "                        torch.zeros(bs, self.hidden_size).to(x.device))\n",
    "        else:\n",
    "            h_t, c_t = init_states\n",
    "         \n",
    "        HS = self.hidden_size\n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:, t, :]\n",
    "            # batch the computations into a single matrix multiplication\n",
    "            gates = x_t @ self.W + h_t @ self.U + self.bias\n",
    "            i_t, f_t, g_t, o_t = (\n",
    "                torch.sigmoid(gates[:, :HS]), # input\n",
    "                torch.sigmoid(gates[:, HS:HS*2]), # forget\n",
    "                torch.tanh(gates[:, HS*2:HS*3]),\n",
    "                torch.sigmoid(gates[:, HS*3:]), # output\n",
    "            )\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            h_t = self.drop(h_t)\n",
    "            hidden_seq.append(h_t.unsqueeze(0))\n",
    "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
    "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
    "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
    "        return hidden_seq, (h_t, c_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MzY7uCcnkZ5w",
   "metadata": {
    "id": "MzY7uCcnkZ5w"
   },
   "outputs": [],
   "source": [
    "class Model(BertPreTrainedModel):\n",
    "      def __init__(self, config, args):\n",
    "        super(Model, self).__init__(config)\n",
    "        self.bert = BertModel(config=config)  # Load pretrained bert\n",
    "        # for param in self.bert.parameters():\n",
    "        #   param.requires_grad = False\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "        self.num_domain = args.num_domains\n",
    "        self.out_layer = FCLayer(2*args.lstm_hid, args.num_labels, use_activation='None', dropout_rate=0.2)\n",
    "        self.fc_layer = FCLayer(config.hidden_size*2, config.hidden_size, use_activation='relu', dropout_rate=0.2)\n",
    "        # self.cnn_extract = CNN_Feature(config.hidden_size)\n",
    "        # self.drop = nn.Dropout(args.dropout_rate)\n",
    "        self.lamb = args.lamb\n",
    "        self.grl = GRL()\n",
    "        self.domain_layer = FCLayer(2*args.lstm_hid, args.num_domains, use_activation='None', dropout_rate=0.2)\n",
    "        \n",
    "\n",
    "        self.lstm_tar_fw = CustomLSTM(config.hidden_size, args.lstm_hid, droprate = args.dropout_rate)\n",
    "        self.lstm_tar_bw = CustomLSTM(config.hidden_size, args.lstm_hid, droprate = args.dropout_rate)\n",
    "        self.lstm_sent_fw = CustomLSTM(config.hidden_size, args.lstm_hid, droprate = args.dropout_rate)\n",
    "        self.lstm_sent_bw = CustomLSTM(config.hidden_size, args.lstm_hid, droprate = args.dropout_rate)\n",
    "        self.attention_tar = FCLayer(2*args.lstm_hid, 4*args.lstm_hid, use_activation='None')\n",
    "        self.attention_sent = FCLayer(2*args.lstm_hid, 4*args.lstm_hid, use_activation='None')\n",
    "        self.attention_layer = FCLayer(4*args.lstm_hid, 1, use_activation='None', set_bias=False)\n",
    "        self.max_len_sent = 500\n",
    "        self.hid = args.lstm_hid\n",
    "      def forward(self, ids_1, masks_1, token_types_1, ids_2, masks_2, token_types_2, labels, dom_labels):\n",
    "        #BERT feature extractor\n",
    "        outputs = self.bert(input_ids=ids_1, attention_mask=masks_1, token_type_ids=token_types_1) # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        pooled_output_1 = outputs[2][-1]\n",
    "        # pooled_output_1 = torch.cat((outputs[2][-1],outputs[2][-2], outputs[2][-3],outputs[2][-4]),2)\n",
    "        # pooled_output_1 = self.fc_layer(pooled_output_1)\n",
    "        # pooled_output_1 = torch.cat((outputs[2][-1][:,0,:],outputs[2][-2][:,0,:],outputs[2][-3][:,0,:],outputs[2][-4][:,0,:]),1) # [CLS] batch x 768\n",
    "        outputs = self.bert(input_ids=ids_2, attention_mask=masks_2, token_type_ids=token_types_2) # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        pooled_output_2 = outputs[2][-1]\n",
    "        # pooled_output_2 = torch.cat((outputs[2][-1],outputs[2][-2],outputs[2][-3],outputs[2][-4]),2)\n",
    "        # print(pooled_output_2.size(), pooled_output_2.is_cuda)\n",
    "        # pooled_output_2 = torch.cat((outputs[2][-1][:,0,:],outputs[2][-2][:,0,:],outputs[2][-3][:,0,:],outputs[2][-4][:,0,:]),1) # [CLS] batch x 768\n",
    "        # pooled_output_1 = self.cnn_extract(pooled_output_1)\n",
    "        # pooled_output_2 = self.cnn_extract(pooled_output_2)\n",
    "        # print(torch.cat((pooled_output_1, pooled_output_2), dim=1).size())\n",
    "\n",
    "        ##BiCond\n",
    "        ###FORWARD\n",
    "        #Target\n",
    "        fw_tar_outputs , fw_tar_lst_state = self.lstm_tar_fw(pooled_output_1)\n",
    "        # fw_tar_outputs = self.dropout(fw_tar_outputs)\n",
    "        #Sentence\n",
    "        fw_sent_outputs, fw_last = self.lstm_sent_fw(pooled_output_2, fw_tar_lst_state)\n",
    "        # fw_sent_outputs = self.dropout(fw_sent_outputs)\n",
    "        # print(\"forward target outputs\", fw_tar_outputs.size())\n",
    "        # print(\"forward sent outputs\", fw_sent_outputs.size())\n",
    "\n",
    "        ###BACKWARD\n",
    "        #Target - start from last -> flip\n",
    "        bw_tar_outputs , bw_tar_lst_state = self.lstm_tar_bw(pooled_output_1.flip(dims=[1]))  \n",
    "        # bw_tar_outputs = self.dropout(bw_tar_outputs)\n",
    "        #Sentence - start from last -> flip\n",
    "        bw_sent_outputs, bw_last = self.lstm_sent_bw(pooled_output_2.flip(dims=[1]), bw_tar_lst_state)\n",
    "        # bw_sent_outputs = self.dropout(bw_sent_outputs)\n",
    "        # att_out = torch.cat((fw_last[0],bw_last[0]), dim=1)\n",
    "\n",
    "        concat_sent = torch.cat((fw_sent_outputs,bw_sent_outputs.flip(dims=[1])), dim=2)     #batch x seq x 2*hid\n",
    "        \n",
    "        # concat_sent = self.dropout(concat_sent)\n",
    "        b_size = concat_sent.size(0)\n",
    "        seq = concat_sent.size(1)\n",
    "        hid_dim = concat_sent.size(2)        \n",
    "        concat_sent_1 = concat_sent.view(-1, hid_dim)\n",
    "        concat_sent_1 = self.attention_sent(concat_sent_1)\n",
    "        concat_sent_1 = concat_sent_1.view(b_size, seq, -1)\n",
    "        concat_target = torch.cat((fw_tar_outputs[:,-1],bw_tar_outputs[:,-1]), dim=1)   #batch x 2*hid\n",
    "        # concat_target = self.dropout(concat_target)  \n",
    "        concat_target = self.attention_tar(concat_target)\n",
    "        att = concat_target.unsqueeze(1).repeat(1, 1, self.max_len_sent).view(b_size, seq, -1) + concat_sent_1 #batch x seq x 4*hid\n",
    "        #ATTENTION\n",
    "        ##input: batch x seq x 4*hid -> reshape -> (batch x seq) x 4*hid -> Linear(tanh) -> (batch x seq) x 4*hid -> Linear(none) -> (batch x seq) x 1 \n",
    "        #->reshape -> batch x seq -> softmax -> batch x seq -> batch x 1 x seq\n",
    "        b_size = att.size(0)\n",
    "        att = att.view(-1, 4*self.hid)\n",
    "        att = nn.Tanh()(att)\n",
    "        att = self.attention_layer(att)\n",
    "        att = att.view(b_size, -1).masked_fill_(masks_2==0, -float('inf'))\n",
    "        sm = nn.Softmax(dim=1)\n",
    "        att = sm(att).unsqueeze(1)\n",
    "\n",
    "        #attention output: batch x 1 x seq\n",
    "        #seq input: batch x seq x 2*hid -> bmm -> batch x 1 x 2*hid -> batch x 2*hid\n",
    "        att_out = torch.bmm(att, concat_sent)\n",
    "        # print(\"att_out\", att_out.size())\n",
    "        att_out = att_out.squeeze()\n",
    "\n",
    "        #CLASSIFICATION\n",
    "        # final = torch.cat((pooled_output_1, pooled_output_2), dim=1)\n",
    "        final = att_out\n",
    "        # final = self.fc_layer(final)\n",
    "        preds = self.out_layer(final)\n",
    "        # preds = nn.LogSoftmax(dim=1)(preds)\n",
    "        preds = nn.Sigmoid()(preds)\n",
    "        #Calculate losses\n",
    "        loss_fct = nn.BCELoss()\n",
    "        l_rel = loss_fct(preds.squeeze(), labels.float().view(-1))\n",
    "\n",
    "        ##GRL\n",
    "        grl = self.grl(final)\n",
    "        loss_fct = nn.NLLLoss(reduction='mean')\n",
    "        domain = nn.LogSoftmax(dim=1)(self.domain_layer(grl))\n",
    "        l_domain = loss_fct(domain.view(-1, self.num_domain), dom_labels.long().view(-1))  \n",
    "        loss = l_rel + self.lamb*l_domain\n",
    "\n",
    "        return loss, preds, l_rel, l_domain, domain, outputs[-1]  #loss, logits, loss_stance, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x_MthU_YkZ5w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x_MthU_YkZ5w",
    "outputId": "4c1372f0-eb35-4b2a-8bbf-bbb85085a277"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10096735187424426"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border = len(df_train[df_train[\"relevant\"] == 1]) / len(df_train[\"relevant\"])\n",
    "border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58LpGEXdkZ5w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58LpGEXdkZ5w",
    "outputId": "46d6fe02-ef01-49fe-9121-a3571e172e50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['q-461', 'q-32', 'q-229', 'q-370', 'q-150', 'q-253', 'q-164',\n",
       "       'q-275', 'q-214', 'q-166', 'q-448', 'q-350', 'q-366', 'q-153',\n",
       "       'q-349', 'q-502', 'q-243', 'q-189', 'q-53', 'q-581', 'q-382',\n",
       "       'q-420', 'q-400', 'q-315', 'q-207', 'q-24', 'q-157', 'q-197',\n",
       "       'q-86', 'q-111', 'q-190', 'q-322', 'q-248', 'q-241', 'q-124',\n",
       "       'q-7', 'q-493', 'q-154', 'q-356', 'q-392', 'q-51', 'q-109',\n",
       "       'q-199', 'q-130', 'q-445', 'q-140', 'q-363', 'q-545', 'q-100',\n",
       "       'q-42', 'q-531', 'q-294', 'q-251', 'q-449', 'q-17', 'q-413',\n",
       "       'q-145', 'q-480', 'q-418', 'q-313', 'q-569', 'q-288', 'q-458',\n",
       "       'q-179', 'q-510', 'q-260', 'q-467', 'q-202', 'q-269', 'q-84',\n",
       "       'q-592', 'q-266', 'q-411', 'q-552', 'q-83', 'q-169', 'q-177',\n",
       "       'q-474', 'q-90', 'q-404', 'q-589', 'q-310', 'q-561'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_ids = df_val['question_id'].unique()\n",
    "question_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0iSa_ZppkZ5x",
   "metadata": {
    "id": "0iSa_ZppkZ5x"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    # print(preds)\n",
    "    # print(labels)\n",
    "    return acc_and_f1(preds, labels)\n",
    "\n",
    "\n",
    "def simple_accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "\n",
    "def acc_and_f1(preds, labels, average=\"macro\"):\n",
    "    predict = np.where(preds < border, 0, 1)\n",
    "\n",
    "    acc = simple_accuracy(predict, labels)\n",
    "    report = classification_report(labels, predict, target_names=['none', 'rel'], output_dict=True)\n",
    "\n",
    "    f2_macro = 0  \n",
    "    for id in question_ids:\n",
    "      indexs = df_val[df_val['question_id']==id].index.values\n",
    "      fbeta_pred = predict[indexs]\n",
    "      fbeta_label = labels[indexs]\n",
    "#       print(\"ID \",id)\n",
    "#       print(\"indexs \",indexs)\n",
    "#       print(\"pred\",fbeta_pred)\n",
    "#       print(\"label\",fbeta_label)\n",
    "      f2_macro += fbeta_score(fbeta_label, fbeta_pred, beta=2) / len(question_ids)\n",
    "\n",
    "    f1_none = report['none']['f1-score']\n",
    "    f1_favor = report['rel']['f1-score']\n",
    "    p_none = report['none']['precision']\n",
    "    p_favor = report['rel']['precision']\n",
    "    r_none = report['none']['recall']\n",
    "    r_favor = report['rel']['recall']\n",
    "\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"f2_macro\": f2_macro,\n",
    "        \"p_none\": p_none,\n",
    "        \"p_rel\": p_favor,\n",
    "        \"r_rel\": r_favor,\n",
    "        \"r_none\": r_none,\n",
    "    }\n",
    "\n",
    "def init_logger():\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    "    )\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if not args.no_cuda and torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KkKHMRcckZ5x",
   "metadata": {
    "id": "KkKHMRcckZ5x"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lhLavjeOkZ5x",
   "metadata": {
    "id": "lhLavjeOkZ5x"
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, args, train_dataset=None, dev_dataset=None, test_dataset=None):\n",
    "        self.args = args\n",
    "        self.train_dataset = train_dataset\n",
    "        self.dev_dataset = dev_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.epochs_stop = args.early_stop\n",
    "        self.num_labels = args.num_labels\n",
    "\n",
    "        self.config = BertConfig.from_pretrained(\n",
    "            args.model_name_or_path,\n",
    "            num_labels=self.num_labels,\n",
    "            finetuning_task='VNLaw-BERT',\n",
    "            output_hidden_states=True,\n",
    "            output_attentions=True,\n",
    "        )\n",
    "        self.model = Model.from_pretrained(args.model_name_or_path, config=self.config, args=args)\n",
    "        # self.model.resize_token_embeddings(len(tokenizer)) \n",
    "\n",
    "        # GPU or CPU\n",
    "        self.device = 'cuda' if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def train(self):\n",
    "        train_dataloader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            shuffle=True,\n",
    "            batch_size=self.args.train_batch_size,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "        if self.args.max_steps > 0:\n",
    "            t_total = self.args.max_steps\n",
    "            self.args.num_train_epochs = (\n",
    "                self.args.max_steps // (len(train_dataloader) // self.args.gradient_accumulation_steps) + 1\n",
    "            )\n",
    "        else:\n",
    "            t_total = len(train_dataloader) // self.args.gradient_accumulation_steps * self.args.num_train_epochs\n",
    "\n",
    "        # Prepare optimizer and schedule (linear warmup and decay)\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": args.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = optim.AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=self.args.learning_rate,\n",
    "            eps=self.args.adam_epsilon,\n",
    "        )\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.args.learning_rate)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.args.warmup_steps,\n",
    "            num_training_steps=t_total,\n",
    "        )\n",
    "\n",
    "\n",
    "        # Train!\n",
    "        self.args.logging_steps = t_total // self.args.num_train_epochs\n",
    "        self.args.save_steps    = t_total // self.args.num_train_epochs\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(self.train_dataset))\n",
    "        logger.info(\"  Num Epochs = %d\", self.args.num_train_epochs)\n",
    "        logger.info(\"  Total train batch size = %d\", self.args.train_batch_size)\n",
    "        logger.info(\"  Gradient Accumulation steps = %d\", self.args.gradient_accumulation_steps)\n",
    "        logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "        logger.info(\"  Logging steps = %d\", self.args.logging_steps)\n",
    "        logger.info(\"  Save steps = %d\", self.args.save_steps)\n",
    "\n",
    "        global_step = 0\n",
    "        tr_loss = 0.0\n",
    "        tr_loss_rel = 0.0\n",
    "        tr_loss_domain = 0.0\n",
    "        max_val_score = -1\n",
    "        early_stop = False\n",
    "        epochs_no_improve = 0 \n",
    "\n",
    "        # train_iterator = trange(int(self.args.num_train_epochs), desc=\"Epoch\") \n",
    "        for epoch_cnt in range(self.args.num_train_epochs):\n",
    "            start = time.time()\n",
    "            self.model.train()\n",
    "\n",
    "            # epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                batch = tuple(t.unsqueeze(0).to(self.device) if t.dim()==1 else t.to(self.device) for t in batch)  # GPU or CPU\n",
    "                inputs = {\n",
    "                    \"ids_1\": batch[0],\n",
    "                    \"masks_1\": batch[1],\n",
    "                    \"token_types_1\": batch[2],\n",
    "                    \"ids_2\": batch[3],\n",
    "                    \"masks_2\": batch[4],\n",
    "                    \"token_types_2\": batch[5],\n",
    "                    \"labels\": batch[6],\n",
    "                    \"dom_labels\": batch[7],\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                loss = outputs[0]\n",
    "\n",
    "                if self.args.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / self.args.gradient_accumulation_steps\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                tr_loss += loss.item()\n",
    "                tr_loss_rel += outputs[2].item()\n",
    "                tr_loss_domain += outputs[3].item()\n",
    "                if (step + 1) % self.args.gradient_accumulation_steps == 0:\n",
    "                    # torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.args.max_grad_norm)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    # scheduler.step()  # Update learning rate schedule\n",
    "\n",
    "                    if step % 100 == 0 or step == (len(train_dataloader) - 1):\n",
    "                        logger.info(\n",
    "                            f\"Epoch: [{epoch_cnt + 1}][{step}/{len(train_dataloader)}] \"\n",
    "                            f\"Elapsed {timeSince(start, float(step + 1) / len(train_dataloader)):s} \"\n",
    "                            f\"Loss: {tr_loss/(global_step+1):.4f} \"\n",
    "                            f\"Loss_rel: {tr_loss_rel/(global_step+1):.4f} \"\n",
    "                            f\"Loss_domain: {tr_loss_domain/(global_step+1):.4f} \"\n",
    "                        )\n",
    "                    global_step += 1\n",
    "\n",
    "                    if self.args.logging_steps > 0 and global_step % self.args.logging_steps == 0:\n",
    "                        res = self.evaluate(\"dev\")\n",
    "                        logger.info(\"Training total loss = %.4f\", tr_loss/global_step)  \n",
    "                        if res['f2_macro']  > max_val_score:\n",
    "                          max_val_score = res['f2_macro']\n",
    "                          final = res\n",
    "                          epochs_no_improve = 0\n",
    "                          self.save_model()\n",
    "                        else:\n",
    "                          epochs_no_improve += 1\n",
    "                        \n",
    "                        if epochs_no_improve == self.epochs_stop:\n",
    "                          early_stop = True\n",
    "                          logger.info(\" Early Stopping!!!!!!\")\n",
    "                          logger.info(\"***** Final results *****\")\n",
    "                          for key in sorted(final.keys()):\n",
    "                              logger.info(\"  {} = {:.4f}\".format(key, final[key]))\n",
    "                          break\n",
    "\n",
    "                    # if self.args.save_steps > 0 and global_step % self.args.save_steps == 0:\n",
    "                    #     self.save_model()\n",
    "\n",
    "                if 0 < self.args.max_steps < global_step or early_stop==True:\n",
    "                    epoch_iterator.close()\n",
    "                    break\n",
    "            \n",
    "            if 0 < self.args.max_steps < global_step or early_stop==True:\n",
    "                train_iterator.close()\n",
    "                break\n",
    "\n",
    "        return global_step, tr_loss / global_step\n",
    "\n",
    "    def evaluate(self, mode, out_pred=False):\n",
    "        # We use test dataset because semeval doesn't have dev dataset\n",
    "        if mode == \"test\":\n",
    "            dataset = self.test_dataset\n",
    "        elif mode == \"dev\":\n",
    "            dataset = self.dev_dataset\n",
    "        else:\n",
    "            raise Exception(\"Only dev and test dataset available\")\n",
    "\n",
    "        eval_sampler = SequentialSampler(dataset)\n",
    "        eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=self.args.eval_batch_size)\n",
    "\n",
    "        # Eval!\n",
    "        logger.info(\"***** Running evaluation on %s dataset *****\", mode)\n",
    "        logger.info(\"  Num examples = %d\", len(dataset))\n",
    "        logger.info(\"  Batch size = %d\", self.args.eval_batch_size)\n",
    "        eval_loss = 0.0\n",
    "        eval_loss_rel = 0.0\n",
    "        eval_loss_domain = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        for batch in eval_dataloader:\n",
    "            start = time.time()\n",
    "            batch = tuple(t.unsqueeze(0).to(self.device) if t.dim()==1 else t.to(self.device) for t in batch)  \n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                    \"ids_1\": batch[0],\n",
    "                    \"masks_1\": batch[1],\n",
    "                    \"token_types_1\": batch[2],\n",
    "                    \"ids_2\": batch[3],\n",
    "                    \"masks_2\": batch[4],\n",
    "                    \"token_types_2\": batch[5],\n",
    "                    \"labels\": batch[6],\n",
    "                    \"dom_labels\": batch[7],\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                logits, tmp_eval_loss = outputs[1],outputs[0]\n",
    "                # print(tmp_eval_loss)\n",
    "                eval_loss += tmp_eval_loss.item()\n",
    "                eval_loss_rel += outputs[2].item()\n",
    "                eval_loss_domain += outputs[3].item()\n",
    "            if nb_eval_steps % 100 == 0 or nb_eval_steps == (len(eval_dataloader) - 1):\n",
    "                logger.info(\n",
    "                            f\"VAL: [{nb_eval_steps}/{len(eval_dataloader)}] \"\n",
    "                            f\"Elapsed {timeSince(start, float(nb_eval_steps + 1) / len(eval_dataloader)):s} \"\n",
    "                            f\"Loss: {eval_loss/(nb_eval_steps+1):.4f} \"\n",
    "                            f\"Loss_rel: {eval_loss_rel/(nb_eval_steps+1):.4f} \"\n",
    "                            f\"Loss_domain: {eval_loss_domain/(nb_eval_steps+1):.4f} \"\n",
    "                        )\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "            if preds is None:\n",
    "                preds = logits.view(-1).detach().cpu().numpy()\n",
    "                out_label_ids = inputs[\"labels\"].view(-1).detach().cpu().numpy()\n",
    "                # att_weights = outputs[-1].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.view(-1).detach().cpu().numpy(), axis=0)\n",
    "                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].view(-1).detach().cpu().numpy(), axis=0)\n",
    "                # att_weights = np.append(att_weights, outputs[-1].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        results = {\"loss\": eval_loss}\n",
    "        # print(preds)\n",
    "        # preds = np.argmax(preds, axis=1)\n",
    "        # write_prediction(self.args, os.path.join(self.args.eval_dir, \"proposed_answers.txt\"), preds)\n",
    "\n",
    "        result = compute_metrics(preds, out_label_ids)\n",
    "        results.update(result)\n",
    "\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(results.keys()):\n",
    "            logger.info(\"  {} = {:.4f}\".format(key, results[key]))\n",
    "\n",
    "        if out_pred == True:\n",
    "          return preds\n",
    "        return results\n",
    "\n",
    "    def save_model(self):\n",
    "        # Save model checkpoint (Overwrite)\n",
    "        if not os.path.exists(self.args.model_dir):\n",
    "            os.makedirs(self.args.model_dir)\n",
    "        model_to_save = self.model.module if hasattr(self.model, \"module\") else self.model\n",
    "        model_to_save.save_pretrained(self.args.model_dir)\n",
    "        # model_to_save = self.model\n",
    "        # torch.save(model_to_save, os.path.join(self.args.model_dir, \"model.pt\"))\n",
    "\n",
    "        # Save training arguments together with the trained model\n",
    "        torch.save(self.args, os.path.join(self.args.model_dir, \"training_args.bin\"))\n",
    "        logger.info(\"Saving model checkpoint to %s\", self.args.model_dir)\n",
    "\n",
    "    def load_model(self):\n",
    "        # Check whether model exists\n",
    "        if not os.path.exists(self.args.model_dir):\n",
    "            raise Exception(\"Model doesn't exists! Train first!\")\n",
    "\n",
    "        self.args = torch.load(os.path.join(self.args.model_dir, \"training_args.bin\"))\n",
    "        self.config = BertConfig.from_pretrained(self.args.model_dir)\n",
    "\n",
    "        self.model = Model.from_pretrained(self.args.model_dir, config=self.config, args=self.args)\n",
    "        # self.model = torch.load(os.path.join(self.args.model_dir, \"model.pt\"))\n",
    "        self.model.to(self.device)\n",
    "        logger.info(\"***** Model Loaded *****\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PgGWqOSWkZ5y",
   "metadata": {
    "id": "PgGWqOSWkZ5y"
   },
   "outputs": [],
   "source": [
    "def main(args, train_data, valid_data):\n",
    "    init_logger()\n",
    "    set_seed(args)\n",
    "\n",
    "    trainer = Trainer(args, train_dataset=train_data, dev_dataset=val_data)\n",
    "    if args.do_train:\n",
    "        trainer.train()\n",
    "\n",
    "    if args.do_eval:\n",
    "        trainer.load_model()\n",
    "        trainer.evaluate(\"dev\")\n",
    "        # trainer.evaluate(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5pUV5bSGkZ5y",
   "metadata": {
    "id": "5pUV5bSGkZ5y"
   },
   "outputs": [],
   "source": [
    "class arg():\n",
    "  def __init__(self):\n",
    "    self.model_dir = '/content/drive/MyDrive/vn_law/BERT_task1_1'\n",
    "    self.model_name_or_path = MODEL\n",
    "    self.do_train = True\n",
    "    self.do_eval = True\n",
    "    self.no_cuda = False\n",
    "    # self.logging_steps = 13         #Log every X updates steps\n",
    "    # self.save_steps = 13            #Save checkpoint every X updates steps\n",
    "    self.warmup_steps = 0\n",
    "    self.max_grad_norm = 1.0\n",
    "    self.adam_epsilon = 1e-8\n",
    "    self.weight_decay = 0.01\n",
    "    self.dropout_rate = 0.2\n",
    "    self.max_steps = -1              #total number of training steps to perform\n",
    "    self.gradient_accumulation_steps = 1     #Number of updates steps to accumulate before performing a backward/update pass\n",
    "    self.num_train_epochs = 10\n",
    "    self.learning_rate = 2e-5\n",
    "    self.early_stop = 35\n",
    "    self.train_batch_size = 8\n",
    "    self.eval_batch_size = 8\n",
    "    self.seed = 2020\n",
    "    self.num_labels = 1\n",
    "    self.lamb = 0.03\n",
    "    self.lstm_hid = 500\n",
    "    self.num_domains = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LA5e-VqWkZ5y",
   "metadata": {
    "id": "LA5e-VqWkZ5y"
   },
   "outputs": [],
   "source": [
    "args = arg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceFrtl7NkZ5y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ceFrtl7NkZ5y",
    "outputId": "31a4aeaa-914d-4b04-b313-fdf848a2b225"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type ibert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-810000 were not used when initializing Model: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Model were not initialized from the model checkpoint at /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-810000 and are newly initialized: ['lstm_sent_fw.bias', 'domain_layer.linear.bias', 'fc_layer.linear.weight', 'lstm_tar_fw.U', 'attention_tar.linear.weight', 'lstm_tar_bw.U', 'lstm_sent_bw.bias', 'attention_sent.linear.bias', 'lstm_sent_bw.W', 'bert.pooler.dense.weight', 'lstm_sent_fw.U', 'attention_layer.linear.weight', 'lstm_tar_bw.bias', 'lstm_tar_bw.W', 'fc_layer.linear.bias', 'out_layer.linear.bias', 'domain_layer.linear.weight', 'lstm_tar_fw.bias', 'lstm_sent_bw.U', 'attention_sent.linear.weight', 'bert.pooler.dense.bias', 'lstm_sent_fw.W', 'lstm_tar_fw.W', 'attention_tar.linear.bias', 'out_layer.linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "08/24/2021 07:33:17 - INFO - __main__ -   ***** Running training *****\n",
      "08/24/2021 07:33:17 - INFO - __main__ -     Num examples = 3308\n",
      "08/24/2021 07:33:17 - INFO - __main__ -     Num Epochs = 10\n",
      "08/24/2021 07:33:17 - INFO - __main__ -     Total train batch size = 8\n",
      "08/24/2021 07:33:17 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "08/24/2021 07:33:17 - INFO - __main__ -     Total optimization steps = 4130\n",
      "08/24/2021 07:33:17 - INFO - __main__ -     Logging steps = 413\n",
      "08/24/2021 07:33:17 - INFO - __main__ -     Save steps = 413\n",
      "08/24/2021 07:33:19 - INFO - __main__ -   Epoch: [1][0/413] Elapsed 0m 2s (remain 14m 36s) Loss: 0.7741 Loss_rel: 0.6910 Loss_domain: 2.7684 \n",
      "08/24/2021 07:36:33 - INFO - __main__ -   Epoch: [1][100/413] Elapsed 3m 15s (remain 10m 4s) Loss: 0.4293 Loss_rel: 0.3451 Loss_domain: 2.8083 \n",
      "08/24/2021 07:39:46 - INFO - __main__ -   Epoch: [1][200/413] Elapsed 6m 28s (remain 6m 50s) Loss: 0.4101 Loss_rel: 0.3254 Loss_domain: 2.8234 \n",
      "08/24/2021 07:42:59 - INFO - __main__ -   Epoch: [1][300/413] Elapsed 9m 41s (remain 3m 36s) Loss: 0.4086 Loss_rel: 0.3234 Loss_domain: 2.8397 \n",
      "08/24/2021 07:46:13 - INFO - __main__ -   Epoch: [1][400/413] Elapsed 12m 55s (remain 0m 23s) Loss: 0.4144 Loss_rel: 0.3290 Loss_domain: 2.8480 \n",
      "08/24/2021 07:46:36 - INFO - __main__ -   Epoch: [1][412/413] Elapsed 13m 18s (remain 0m 0s) Loss: 0.4141 Loss_rel: 0.3287 Loss_domain: 2.8485 \n",
      "08/24/2021 07:46:36 - INFO - __main__ -   ***** Running evaluation on dev dataset *****\n",
      "08/24/2021 07:46:36 - INFO - __main__ -     Num examples = 832\n",
      "08/24/2021 07:46:36 - INFO - __main__ -     Batch size = 8\n",
      "08/24/2021 07:46:37 - INFO - __main__ -   VAL: [0/104] Elapsed 0m 0s (remain 0m 50s) Loss: 1.8434 Loss_rel: 1.7568 Loss_domain: 2.8844 \n",
      "08/24/2021 07:47:24 - INFO - __main__ -   VAL: [100/104] Elapsed 0m 0s (remain 0m 0s) Loss: 0.4067 Loss_rel: 0.3189 Loss_domain: 2.9282 \n",
      "08/24/2021 07:47:25 - INFO - __main__ -   VAL: [103/104] Elapsed 0m 0s (remain 0m 0s) Loss: 0.4010 Loss_rel: 0.3132 Loss_domain: 2.9246 \n",
      "08/24/2021 07:47:25 - INFO - __main__ -   ***** Eval results *****\n",
      "08/24/2021 07:47:25 - INFO - __main__ -     acc = 0.6130\n",
      "08/24/2021 07:47:25 - INFO - __main__ -     f2_macro = 0.2907\n",
      "08/24/2021 07:47:25 - INFO - __main__ -     loss = 0.4010\n",
      "08/24/2021 07:47:25 - INFO - __main__ -     p_none = 0.9208\n",
      "08/24/2021 07:47:25 - INFO - __main__ -     p_rel = 0.1376\n",
      "08/24/2021 07:47:25 - INFO - __main__ -     r_none = 0.6225\n",
      "08/24/2021 07:47:25 - INFO - __main__ -     r_rel = 0.5294\n",
      "08/24/2021 07:47:25 - INFO - __main__ -   Training total loss = 0.4141\n",
      "08/24/2021 07:47:29 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/vn_law/BERT_task1_test\n",
      "08/24/2021 07:47:31 - INFO - __main__ -   Epoch: [2][0/413] Elapsed 0m 1s (remain 13m 19s) Loss: 0.4143 Loss_rel: 0.3288 Loss_domain: 2.8488 \n",
      "08/24/2021 07:50:46 - INFO - __main__ -   Epoch: [2][100/413] Elapsed 3m 16s (remain 10m 5s) Loss: 0.4041 Loss_rel: 0.3186 Loss_domain: 2.8484 \n",
      "08/24/2021 07:53:59 - INFO - __main__ -   Epoch: [2][200/413] Elapsed 6m 29s (remain 6m 50s) Loss: 0.4072 Loss_rel: 0.3218 Loss_domain: 2.8455 \n",
      "08/24/2021 07:57:13 - INFO - __main__ -   Epoch: [2][300/413] Elapsed 9m 43s (remain 3m 37s) Loss: 0.4085 Loss_rel: 0.3234 Loss_domain: 2.8363 \n",
      "08/24/2021 08:00:26 - INFO - __main__ -   Epoch: [2][400/413] Elapsed 12m 56s (remain 0m 23s) Loss: 0.4100 Loss_rel: 0.3253 Loss_domain: 2.8236 \n",
      "08/24/2021 08:00:49 - INFO - __main__ -   Epoch: [2][412/413] Elapsed 13m 19s (remain 0m 0s) Loss: 0.4096 Loss_rel: 0.3249 Loss_domain: 2.8218 \n",
      "08/24/2021 08:00:49 - INFO - __main__ -   ***** Running evaluation on dev dataset *****\n",
      "08/24/2021 08:00:49 - INFO - __main__ -     Num examples = 832\n",
      "08/24/2021 08:00:49 - INFO - __main__ -     Batch size = 8\n",
      "08/24/2021 08:00:50 - INFO - __main__ -   VAL: [0/104] Elapsed 0m 0s (remain 0m 49s) Loss: 2.4438 Loss_rel: 2.3663 Loss_domain: 2.5843 \n",
      "08/24/2021 08:01:36 - INFO - __main__ -   VAL: [100/104] Elapsed 0m 0s (remain 0m 0s) Loss: 0.4160 Loss_rel: 0.3363 Loss_domain: 2.6553 \n",
      "08/24/2021 08:01:38 - INFO - __main__ -   VAL: [103/104] Elapsed 0m 0s (remain 0m 0s) Loss: 0.4098 Loss_rel: 0.3300 Loss_domain: 2.6587 \n",
      "08/24/2021 08:01:38 - INFO - __main__ -   ***** Eval results *****\n",
      "08/24/2021 08:01:38 - INFO - __main__ -     acc = 0.2103\n",
      "08/24/2021 08:01:38 - INFO - __main__ -     f2_macro = 0.2801\n",
      "08/24/2021 08:01:38 - INFO - __main__ -     loss = 0.4098\n",
      "08/24/2021 08:01:38 - INFO - __main__ -     p_none = 0.8214\n",
      "08/24/2021 08:01:38 - INFO - __main__ -     p_rel = 0.0867\n",
      "08/24/2021 08:01:38 - INFO - __main__ -     r_none = 0.1539\n",
      "08/24/2021 08:01:38 - INFO - __main__ -     r_rel = 0.7059\n",
      "08/24/2021 08:01:38 - INFO - __main__ -   Training total loss = 0.4096\n",
      "08/24/2021 08:01:40 - INFO - __main__ -   Epoch: [3][0/413] Elapsed 0m 1s (remain 13m 11s) Loss: 0.4093 Loss_rel: 0.3247 Loss_domain: 2.8215 \n",
      "08/24/2021 08:04:53 - INFO - __main__ -   Epoch: [3][100/413] Elapsed 3m 15s (remain 10m 3s) Loss: 0.4072 Loss_rel: 0.3230 Loss_domain: 2.8069 \n",
      "08/24/2021 08:08:07 - INFO - __main__ -   Epoch: [3][200/413] Elapsed 6m 28s (remain 6m 50s) Loss: 0.4079 Loss_rel: 0.3242 Loss_domain: 2.7911 \n",
      "08/24/2021 08:11:20 - INFO - __main__ -   Epoch: [3][300/413] Elapsed 9m 42s (remain 3m 36s) Loss: 0.4081 Loss_rel: 0.3247 Loss_domain: 2.7775 \n",
      "08/24/2021 08:14:34 - INFO - __main__ -   Epoch: [3][400/413] Elapsed 12m 55s (remain 0m 23s) Loss: 0.4060 Loss_rel: 0.3231 Loss_domain: 2.7650 \n",
      "08/24/2021 08:14:57 - INFO - __main__ -   Epoch: [3][412/413] Elapsed 13m 19s (remain 0m 0s) Loss: 0.4065 Loss_rel: 0.3236 Loss_domain: 2.7642 \n",
      "08/24/2021 08:14:57 - INFO - __main__ -   ***** Running evaluation on dev dataset *****\n",
      "08/24/2021 08:14:57 - INFO - __main__ -     Num examples = 832\n",
      "08/24/2021 08:14:57 - INFO - __main__ -     Batch size = 8\n",
      "08/24/2021 08:14:57 - INFO - __main__ -   VAL: [0/104] Elapsed 0m 0s (remain 0m 49s) Loss: 2.0855 Loss_rel: 2.0099 Loss_domain: 2.5176 \n",
      "08/24/2021 08:15:44 - INFO - __main__ -   VAL: [100/104] Elapsed 0m 0s (remain 0m 0s) Loss: 0.3986 Loss_rel: 0.3207 Loss_domain: 2.5957 \n",
      "08/24/2021 08:15:46 - INFO - __main__ -   VAL: [103/104] Elapsed 0m 0s (remain 0m 0s) Loss: 0.3932 Loss_rel: 0.3152 Loss_domain: 2.6012 \n",
      "08/24/2021 08:15:46 - INFO - __main__ -   ***** Eval results *****\n",
      "08/24/2021 08:15:46 - INFO - __main__ -     acc = 0.3810\n",
      "08/24/2021 08:15:46 - INFO - __main__ -     f2_macro = 0.3747\n",
      "08/24/2021 08:15:46 - INFO - __main__ -     loss = 0.3932\n",
      "08/24/2021 08:15:46 - INFO - __main__ -     p_none = 0.9361\n",
      "08/24/2021 08:15:46 - INFO - __main__ -     p_rel = 0.1201\n",
      "08/24/2021 08:15:46 - INFO - __main__ -     r_none = 0.3333\n",
      "08/24/2021 08:15:46 - INFO - __main__ -     r_rel = 0.8000\n",
      "08/24/2021 08:15:46 - INFO - __main__ -   Training total loss = 0.4065\n",
      "08/24/2021 08:15:49 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/vn_law/BERT_task1_test\n",
      "08/24/2021 08:15:51 - INFO - __main__ -   Epoch: [4][0/413] Elapsed 0m 1s (remain 13m 21s) Loss: 0.4066 Loss_rel: 0.3236 Loss_domain: 2.7641 \n",
      "08/24/2021 08:19:05 - INFO - __main__ -   Epoch: [4][100/413] Elapsed 3m 16s (remain 10m 6s) Loss: 0.4065 Loss_rel: 0.3240 Loss_domain: 2.7531 \n",
      "08/24/2021 08:22:19 - INFO - __main__ -   Epoch: [4][200/413] Elapsed 6m 29s (remain 6m 51s) Loss: 0.4061 Loss_rel: 0.3237 Loss_domain: 2.7449 \n",
      "08/24/2021 08:25:32 - INFO - __main__ -   Epoch: [4][300/413] Elapsed 9m 43s (remain 3m 36s) Loss: 0.4063 Loss_rel: 0.3241 Loss_domain: 2.7387 \n",
      "08/24/2021 08:28:45 - INFO - __main__ -   Epoch: [4][400/413] Elapsed 12m 56s (remain 0m 23s) Loss: 0.4044 Loss_rel: 0.3224 Loss_domain: 2.7321 \n",
      "08/24/2021 08:29:08 - INFO - __main__ -   Epoch: [4][412/413] Elapsed 13m 19s (remain 0m 0s) Loss: 0.4033 Loss_rel: 0.3213 Loss_domain: 2.7319 \n",
      "08/24/2021 08:29:08 - INFO - __main__ -   ***** Running evaluation on dev dataset *****\n",
      "08/24/2021 08:29:08 - INFO - __main__ -     Num examples = 832\n",
      "08/24/2021 08:29:08 - INFO - __main__ -     Batch size = 8\n",
      "08/24/2021 08:29:09 - INFO - __main__ -   VAL: [0/104] Elapsed 0m 0s (remain 0m 48s) Loss: 2.3075 Loss_rel: 2.2317 Loss_domain: 2.5279 \n",
      "08/24/2021 08:29:56 - INFO - __main__ -   VAL: [100/104] Elapsed 0m 0s (remain 0m 0s) Loss: 0.3929 Loss_rel: 0.3168 Loss_domain: 2.5348 \n",
      "08/24/2021 08:29:57 - INFO - __main__ -   VAL: [103/104] Elapsed 0m 0s (remain 0m 0s) Loss: 0.3866 Loss_rel: 0.3102 Loss_domain: 2.5464 \n",
      "08/24/2021 08:29:57 - INFO - __main__ -   ***** Eval results *****\n",
      "08/24/2021 08:29:57 - INFO - __main__ -     acc = 0.8113\n",
      "08/24/2021 08:29:57 - INFO - __main__ -     f2_macro = 0.3018\n",
      "08/24/2021 08:29:57 - INFO - __main__ -     loss = 0.3866\n",
      "08/24/2021 08:29:57 - INFO - __main__ -     p_none = 0.9239\n",
      "08/24/2021 08:29:57 - INFO - __main__ -     p_rel = 0.2353\n",
      "08/24/2021 08:29:57 - INFO - __main__ -     r_none = 0.8608\n",
      "08/24/2021 08:29:57 - INFO - __main__ -     r_rel = 0.3765\n",
      "08/24/2021 08:29:57 - INFO - __main__ -   Training total loss = 0.4033\n",
      "08/24/2021 08:29:59 - INFO - __main__ -   Epoch: [5][0/413] Elapsed 0m 1s (remain 13m 18s) Loss: 0.4031 Loss_rel: 0.3212 Loss_domain: 2.7320 \n",
      "08/24/2021 08:33:13 - INFO - __main__ -   Epoch: [5][100/413] Elapsed 3m 15s (remain 10m 3s) Loss: 0.4012 Loss_rel: 0.3195 Loss_domain: 2.7255 \n",
      "08/24/2021 08:36:26 - INFO - __main__ -   Epoch: [5][200/413] Elapsed 6m 28s (remain 6m 50s) Loss: 0.4006 Loss_rel: 0.3190 Loss_domain: 2.7232 \n",
      "08/24/2021 08:39:40 - INFO - __main__ -   Epoch: [5][300/413] Elapsed 9m 42s (remain 3m 36s) Loss: 0.4006 Loss_rel: 0.3189 Loss_domain: 2.7218 \n",
      "08/24/2021 08:42:54 - INFO - __main__ -   Epoch: [5][400/413] Elapsed 12m 56s (remain 0m 23s) Loss: 0.3986 Loss_rel: 0.3169 Loss_domain: 2.7229 \n",
      "08/24/2021 08:43:17 - INFO - __main__ -   Epoch: [5][412/413] Elapsed 13m 19s (remain 0m 0s) Loss: 0.3992 Loss_rel: 0.3175 Loss_domain: 2.7233 \n",
      "08/24/2021 08:43:17 - INFO - __main__ -   ***** Running evaluation on dev dataset *****\n",
      "08/24/2021 08:43:17 - INFO - __main__ -     Num examples = 832\n",
      "08/24/2021 08:43:17 - INFO - __main__ -     Batch size = 8\n",
      "08/24/2021 08:43:18 - INFO - __main__ -   VAL: [0/104] Elapsed 0m 0s (remain 0m 50s) Loss: 1.5908 Loss_rel: 1.5123 Loss_domain: 2.6162 \n",
      "08/24/2021 08:44:05 - INFO - __main__ -   VAL: [100/104] Elapsed 0m 0s (remain 0m 0s) Loss: 0.4136 Loss_rel: 0.3316 Loss_domain: 2.7339 \n",
      "08/24/2021 08:44:06 - INFO - __main__ -   VAL: [103/104] Elapsed 0m 0s (remain 0m 0s) Loss: 0.4092 Loss_rel: 0.3269 Loss_domain: 2.7432 \n",
      "08/24/2021 08:44:06 - INFO - __main__ -   ***** Eval results *****\n",
      "08/24/2021 08:44:06 - INFO - __main__ -     acc = 0.3810\n",
      "08/24/2021 08:44:06 - INFO - __main__ -     f2_macro = 0.3981\n",
      "08/24/2021 08:44:06 - INFO - __main__ -     loss = 0.4092\n",
      "08/24/2021 08:44:06 - INFO - __main__ -     p_none = 0.9531\n",
      "08/24/2021 08:44:06 - INFO - __main__ -     p_rel = 0.1267\n",
      "08/24/2021 08:44:06 - INFO - __main__ -     r_none = 0.3266\n",
      "08/24/2021 08:44:06 - INFO - __main__ -     r_rel = 0.8588\n",
      "08/24/2021 08:44:06 - INFO - __main__ -   Training total loss = 0.3992\n",
      "08/24/2021 08:44:09 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/vn_law/BERT_task1_test\n",
      "08/24/2021 08:44:11 - INFO - __main__ -   Epoch: [6][0/413] Elapsed 0m 1s (remain 13m 32s) Loss: 0.3992 Loss_rel: 0.3175 Loss_domain: 2.7232 \n",
      "08/24/2021 08:47:25 - INFO - __main__ -   Epoch: [6][100/413] Elapsed 3m 16s (remain 10m 6s) Loss: 0.3983 Loss_rel: 0.3166 Loss_domain: 2.7234 \n",
      "08/24/2021 08:50:39 - INFO - __main__ -   Epoch: [6][200/413] Elapsed 6m 30s (remain 6m 51s) Loss: 0.3977 Loss_rel: 0.3161 Loss_domain: 2.7214 \n",
      "08/24/2021 08:53:53 - INFO - __main__ -   Epoch: [6][300/413] Elapsed 9m 43s (remain 3m 37s) Loss: 0.3964 Loss_rel: 0.3149 Loss_domain: 2.7187 \n",
      "08/24/2021 08:57:06 - INFO - __main__ -   Epoch: [6][400/413] Elapsed 12m 57s (remain 0m 23s) Loss: 0.3947 Loss_rel: 0.3131 Loss_domain: 2.7194 \n",
      "08/24/2021 08:57:30 - INFO - __main__ -   Epoch: [6][412/413] Elapsed 13m 20s (remain 0m 0s) Loss: 0.3947 Loss_rel: 0.3131 Loss_domain: 2.7193 \n",
      "08/24/2021 08:57:30 - INFO - __main__ -   ***** Running evaluation on dev dataset *****\n",
      "08/24/2021 08:57:30 - INFO - __main__ -     Num examples = 832\n",
      "08/24/2021 08:57:30 - INFO - __main__ -     Batch size = 8\n",
      "08/24/2021 08:57:30 - INFO - __main__ -   VAL: [0/104] Elapsed 0m 0s (remain 0m 49s) Loss: 2.0932 Loss_rel: 2.0142 Loss_domain: 2.6345 \n",
      "08/24/2021 08:58:17 - INFO - __main__ -   VAL: [100/104] Elapsed 0m 0s (remain 0m 0s) Loss: 0.3845 Loss_rel: 0.3053 Loss_domain: 2.6402 \n",
      "08/24/2021 08:58:18 - INFO - __main__ -   VAL: [103/104] Elapsed 0m 0s (remain 0m 0s) Loss: 0.3797 Loss_rel: 0.3003 Loss_domain: 2.6480 \n",
      "08/24/2021 08:58:19 - INFO - __main__ -   ***** Eval results *****\n",
      "08/24/2021 08:58:19 - INFO - __main__ -     acc = 0.8329\n",
      "08/24/2021 08:58:19 - INFO - __main__ -     f2_macro = 0.2906\n",
      "08/24/2021 08:58:19 - INFO - __main__ -     loss = 0.3797\n",
      "08/24/2021 08:58:19 - INFO - __main__ -     p_none = 0.9246\n",
      "08/24/2021 08:58:19 - INFO - __main__ -     p_rel = 0.2672\n",
      "08/24/2021 08:58:19 - INFO - __main__ -     r_none = 0.8862\n",
      "08/24/2021 08:58:19 - INFO - __main__ -     r_rel = 0.3647\n",
      "08/24/2021 08:58:19 - INFO - __main__ -   Training total loss = 0.3947\n",
      "08/24/2021 08:58:21 - INFO - __main__ -   Epoch: [7][0/413] Elapsed 0m 1s (remain 13m 10s) Loss: 0.3946 Loss_rel: 0.3130 Loss_domain: 2.7193 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a8909e92c93c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-820118805fa0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args, train_data, valid_data)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-71cf06b5026e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0;34m\"dom_labels\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 }\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-0c1e6e5bd897>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids_1, masks_1, token_types_1, ids_2, masks_2, token_types_2, labels, dom_labels)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# fw_tar_outputs = self.dropout(fw_tar_outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m#Sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mfw_sent_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfw_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_sent_fw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfw_tar_lst_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;31m# fw_sent_outputs = self.dropout(fw_sent_outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# print(\"forward target outputs\", fw_tar_outputs.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-9971618151a8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, init_states)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# batch the computations into a single matrix multiplication\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_t\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_t\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             i_t, f_t, g_t, o_t = (\n\u001b[1;32m     35\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mHS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(args, train_data, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nw7V8YvrkZ5y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nw7V8YvrkZ5y",
    "outputId": "35c57211-8686-4507-b364-2223067fe24a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type ibert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-810000 were not used when initializing Model: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Model were not initialized from the model checkpoint at /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-810000 and are newly initialized: ['lstm_sent_fw.bias', 'domain_layer.linear.bias', 'fc_layer.linear.weight', 'lstm_tar_fw.U', 'attention_tar.linear.weight', 'lstm_tar_bw.U', 'lstm_sent_bw.bias', 'attention_sent.linear.bias', 'lstm_sent_bw.W', 'bert.pooler.dense.weight', 'lstm_sent_fw.U', 'attention_layer.linear.weight', 'lstm_tar_bw.bias', 'lstm_tar_bw.W', 'fc_layer.linear.bias', 'out_layer.linear.bias', 'domain_layer.linear.weight', 'lstm_tar_fw.bias', 'lstm_sent_bw.U', 'attention_sent.linear.weight', 'bert.pooler.dense.bias', 'lstm_sent_fw.W', 'lstm_tar_fw.W', 'attention_tar.linear.bias', 'out_layer.linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "08/24/2021 10:00:55 - INFO - __main__ -   ***** Model Loaded *****\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(args, train_dataset=train_data, dev_dataset=val_data)\n",
    "trainer.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1G4SfdA8kZ5z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1G4SfdA8kZ5z",
    "outputId": "cbcfe92a-5320-426b-e5be-8fd40f8ab8ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/24/2021 10:00:55 - INFO - __main__ -   ***** Running evaluation on dev dataset *****\n",
      "08/24/2021 10:00:55 - INFO - __main__ -     Num examples = 832\n",
      "08/24/2021 10:00:55 - INFO - __main__ -     Batch size = 8\n",
      "08/24/2021 10:00:56 - INFO - __main__ -   VAL: [0/104] Elapsed 0m 0s (remain 0m 54s) Loss: 2.3102 Loss_rel: 2.2316 Loss_domain: 2.6190 \n",
      "08/24/2021 10:01:40 - INFO - __main__ -   VAL: [100/104] Elapsed 0m 0s (remain 0m 0s) Loss: 0.3969 Loss_rel: 0.3090 Loss_domain: 2.9300 \n",
      "08/24/2021 10:01:42 - INFO - __main__ -   VAL: [103/104] Elapsed 0m 0s (remain 0m 0s) Loss: 0.3957 Loss_rel: 0.3075 Loss_domain: 2.9413 \n",
      "08/24/2021 10:01:42 - INFO - __main__ -   ***** Eval results *****\n",
      "08/24/2021 10:01:42 - INFO - __main__ -     acc = 0.8606\n",
      "08/24/2021 10:01:42 - INFO - __main__ -     f2_macro = 0.6380\n",
      "08/24/2021 10:01:42 - INFO - __main__ -     loss = 0.3957\n",
      "08/24/2021 10:01:42 - INFO - __main__ -     p_none = 0.9660\n",
      "08/24/2021 10:01:42 - INFO - __main__ -     p_rel = 0.4000\n",
      "08/24/2021 10:01:42 - INFO - __main__ -     r_none = 0.8755\n",
      "08/24/2021 10:01:42 - INFO - __main__ -     r_rel = 0.7294\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.evaluate(\"dev\", out_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RvGv-dSmmtnY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "RvGv-dSmmtnY",
    "outputId": "c9d4c22e-26e0-4b50-a179-93b47af0e4a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question_id</th>\n",
       "      <th>text</th>\n",
       "      <th>law_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_text</th>\n",
       "      <th>relevant</th>\n",
       "      <th>matched_clauses</th>\n",
       "      <th>bert_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>q-461</td>\n",
       "      <td>Mức thù lao luật sư tham gia tố tụng trong vụ ...</td>\n",
       "      <td>123/2013/NĐ-CP</td>\n",
       "      <td>18</td>\n",
       "      <td>Mức trần thù lao luật sư tham gia tố tụng tron...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mức trần thù lao luật sư tham gia tố tụng tron...</td>\n",
       "      <td>0.291835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>q-32</td>\n",
       "      <td>Nhà giáo làm nhiệm vụ giảng dạy, giáo dục tron...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>66</td>\n",
       "      <td>Vị trí, vai trò của nhà giáo\\n\\n1. Nhà giáo là...</td>\n",
       "      <td>1</td>\n",
       "      <td>Vị trí, vai trò của nhà giáo 1. Nhà giáo làm n...</td>\n",
       "      <td>0.230130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>q-229</td>\n",
       "      <td>Người đăng ký hộ tịch trái phép cho 2 người tr...</td>\n",
       "      <td>100/2015/QH13</td>\n",
       "      <td>336</td>\n",
       "      <td>Tội đăng ký hộ tịch trái pháp luật\\n\\n1. Người...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tội đăng ký hộ tịch trái pháp luật 3. Người ph...</td>\n",
       "      <td>0.661736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>q-370</td>\n",
       "      <td>Ủy ban nhân dân tỉnh, thành phố trực thuộc Tru...</td>\n",
       "      <td>45/2013/QH13</td>\n",
       "      <td>30</td>\n",
       "      <td>Bản đồ hành chính\\n\\n1. Bản đồ hành chính của ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bản đồ hành chính 2. Việc lập bản đồ hành chín...</td>\n",
       "      <td>0.948693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>q-150</td>\n",
       "      <td>Người chưa thành niên chưa đủ 13 tuổi chỉ được...</td>\n",
       "      <td>45/2019/QH14</td>\n",
       "      <td>145</td>\n",
       "      <td>Sử dụng người chưa đủ 15 tuổi làm việc\\n\\n1. K...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sử dụng người chưa đủ 15 tuổi làm việc 3. Ngườ...</td>\n",
       "      <td>0.001639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>827</td>\n",
       "      <td>q-561</td>\n",
       "      <td>Mỗi luật sư hướng dẫn chỉ được hướng dẫn không...</td>\n",
       "      <td>21/2010/TT-BTP</td>\n",
       "      <td>6</td>\n",
       "      <td>Thời gian tập sự hành nghề luật sư\\n\\n1. Thời ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Thời gian tập sự hành nghề luật sư 4. Người tậ...</td>\n",
       "      <td>0.002702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>828</td>\n",
       "      <td>q-561</td>\n",
       "      <td>Mỗi luật sư hướng dẫn chỉ được hướng dẫn không...</td>\n",
       "      <td>19/2013/TT-BTP</td>\n",
       "      <td>6</td>\n",
       "      <td>Thời gian tập sự hành nghề luật sư\\n\\n1. Thời ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Thời gian tập sự hành nghề luật sư 4. Người tậ...</td>\n",
       "      <td>0.353408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>829</td>\n",
       "      <td>q-561</td>\n",
       "      <td>Mỗi luật sư hướng dẫn chỉ được hướng dẫn không...</td>\n",
       "      <td>11/2017/QH14</td>\n",
       "      <td>20</td>\n",
       "      <td>Tập sự trợ giúp pháp lý\\n\\n1. Viên chức của Tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>Tập sự trợ giúp pháp lý 1. Viên chức của Trung...</td>\n",
       "      <td>0.001045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>830</td>\n",
       "      <td>q-561</td>\n",
       "      <td>Mỗi luật sư hướng dẫn chỉ được hướng dẫn không...</td>\n",
       "      <td>20/2012/QH13</td>\n",
       "      <td>14</td>\n",
       "      <td>“ Tập sự hành nghề luật sư\\n\\n1. Người có Giấy...</td>\n",
       "      <td>0</td>\n",
       "      <td>“ Tập sự hành nghề luật sư 1. Người có Giấy ch...</td>\n",
       "      <td>0.001319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>831</td>\n",
       "      <td>q-561</td>\n",
       "      <td>Mỗi luật sư hướng dẫn chỉ được hướng dẫn không...</td>\n",
       "      <td>21/2010/TT-BTP</td>\n",
       "      <td>13</td>\n",
       "      <td>Điều kiện đối với luật sư hướng dẫn\\n\\n1. Luật...</td>\n",
       "      <td>0</td>\n",
       "      <td>Điều kiện đối với luật sư hướng dẫn 2. Tại cùn...</td>\n",
       "      <td>0.002563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  ... bert_model\n",
       "0             0  ...   0.291835\n",
       "1             1  ...   0.230130\n",
       "2             2  ...   0.661736\n",
       "3             3  ...   0.948693\n",
       "4             4  ...   0.001639\n",
       "..          ...  ...        ...\n",
       "827         827  ...   0.002702\n",
       "828         828  ...   0.353408\n",
       "829         829  ...   0.001045\n",
       "830         830  ...   0.001319\n",
       "831         831  ...   0.002563\n",
       "\n",
       "[832 rows x 9 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Nu1aSIG6m1tL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "Nu1aSIG6m1tL",
    "outputId": "ee6d5d8d-e681-4797-f9a9-18ef5c2b3060"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question_id</th>\n",
       "      <th>text</th>\n",
       "      <th>law_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_text</th>\n",
       "      <th>relevant</th>\n",
       "      <th>matched_clauses</th>\n",
       "      <th>bert_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>q-461</td>\n",
       "      <td>Mức thù lao luật sư tham gia tố tụng trong vụ ...</td>\n",
       "      <td>123/2013/NĐ-CP</td>\n",
       "      <td>18</td>\n",
       "      <td>Mức trần thù lao luật sư tham gia tố tụng tron...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mức trần thù lao luật sư tham gia tố tụng tron...</td>\n",
       "      <td>0.291835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>q-32</td>\n",
       "      <td>Nhà giáo làm nhiệm vụ giảng dạy, giáo dục tron...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>66</td>\n",
       "      <td>Vị trí, vai trò của nhà giáo\\n\\n1. Nhà giáo là...</td>\n",
       "      <td>1</td>\n",
       "      <td>Vị trí, vai trò của nhà giáo 1. Nhà giáo làm n...</td>\n",
       "      <td>0.230130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>q-229</td>\n",
       "      <td>Người đăng ký hộ tịch trái phép cho 2 người tr...</td>\n",
       "      <td>100/2015/QH13</td>\n",
       "      <td>336</td>\n",
       "      <td>Tội đăng ký hộ tịch trái pháp luật\\n\\n1. Người...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tội đăng ký hộ tịch trái pháp luật 3. Người ph...</td>\n",
       "      <td>0.661736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>q-370</td>\n",
       "      <td>Ủy ban nhân dân tỉnh, thành phố trực thuộc Tru...</td>\n",
       "      <td>45/2013/QH13</td>\n",
       "      <td>30</td>\n",
       "      <td>Bản đồ hành chính\\n\\n1. Bản đồ hành chính của ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bản đồ hành chính 2. Việc lập bản đồ hành chín...</td>\n",
       "      <td>0.948693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>q-150</td>\n",
       "      <td>Người chưa thành niên chưa đủ 13 tuổi chỉ được...</td>\n",
       "      <td>45/2019/QH14</td>\n",
       "      <td>145</td>\n",
       "      <td>Sử dụng người chưa đủ 15 tuổi làm việc\\n\\n1. K...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sử dụng người chưa đủ 15 tuổi làm việc 3. Ngườ...</td>\n",
       "      <td>0.001639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>827</td>\n",
       "      <td>q-561</td>\n",
       "      <td>Mỗi luật sư hướng dẫn chỉ được hướng dẫn không...</td>\n",
       "      <td>21/2010/TT-BTP</td>\n",
       "      <td>6</td>\n",
       "      <td>Thời gian tập sự hành nghề luật sư\\n\\n1. Thời ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Thời gian tập sự hành nghề luật sư 4. Người tậ...</td>\n",
       "      <td>0.002702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>828</td>\n",
       "      <td>q-561</td>\n",
       "      <td>Mỗi luật sư hướng dẫn chỉ được hướng dẫn không...</td>\n",
       "      <td>19/2013/TT-BTP</td>\n",
       "      <td>6</td>\n",
       "      <td>Thời gian tập sự hành nghề luật sư\\n\\n1. Thời ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Thời gian tập sự hành nghề luật sư 4. Người tậ...</td>\n",
       "      <td>0.353408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>829</td>\n",
       "      <td>q-561</td>\n",
       "      <td>Mỗi luật sư hướng dẫn chỉ được hướng dẫn không...</td>\n",
       "      <td>11/2017/QH14</td>\n",
       "      <td>20</td>\n",
       "      <td>Tập sự trợ giúp pháp lý\\n\\n1. Viên chức của Tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>Tập sự trợ giúp pháp lý 1. Viên chức của Trung...</td>\n",
       "      <td>0.001045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>830</td>\n",
       "      <td>q-561</td>\n",
       "      <td>Mỗi luật sư hướng dẫn chỉ được hướng dẫn không...</td>\n",
       "      <td>20/2012/QH13</td>\n",
       "      <td>14</td>\n",
       "      <td>“ Tập sự hành nghề luật sư\\n\\n1. Người có Giấy...</td>\n",
       "      <td>0</td>\n",
       "      <td>“ Tập sự hành nghề luật sư 1. Người có Giấy ch...</td>\n",
       "      <td>0.001319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>831</td>\n",
       "      <td>q-561</td>\n",
       "      <td>Mỗi luật sư hướng dẫn chỉ được hướng dẫn không...</td>\n",
       "      <td>21/2010/TT-BTP</td>\n",
       "      <td>13</td>\n",
       "      <td>Điều kiện đối với luật sư hướng dẫn\\n\\n1. Luật...</td>\n",
       "      <td>0</td>\n",
       "      <td>Điều kiện đối với luật sư hướng dẫn 2. Tại cùn...</td>\n",
       "      <td>0.002563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  ... bert_model\n",
       "0             0  ...   0.291835\n",
       "1             1  ...   0.230130\n",
       "2             2  ...   0.661736\n",
       "3             3  ...   0.948693\n",
       "4             4  ...   0.001639\n",
       "..          ...  ...        ...\n",
       "827         827  ...   0.002702\n",
       "828         828  ...   0.353408\n",
       "829         829  ...   0.001045\n",
       "830         830  ...   0.001319\n",
       "831         831  ...   0.002563\n",
       "\n",
       "[832 rows x 9 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['bert_model'] = preds\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qcIK2lHzmrFN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "qcIK2lHzmrFN",
    "outputId": "82a08eb2-fe1c-43f9-93d9-4165353f36c2"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bm25_score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-32c091998492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbm25_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bm25_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bert_model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbm25_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm25_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bm25_score'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "for q in df_test['question_id'].unique():\n",
    "    scores = df_val[df_val['question_id']==q]\n",
    "    bm25_scores = scores['bm25_score'].values\n",
    "    model_scores = scores['bert_model'].values\n",
    "    bm25_scores = bm25_scores.reshape(-1,1)\n",
    "    # print(bm25_scores)\n",
    "    scaler = MinMaxScaler()\n",
    "    bm25_scores = scaler.fit_transform(bm25_scores)\n",
    "    # print(bm25_scores)\n",
    "    threshold = 0.7\n",
    "    final = threshold*bm25_scores + (1-threshold)*model_scores\n",
    "    print(final.argmax())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X9lcbW8RZnvh",
   "metadata": {
    "id": "X9lcbW8RZnvh"
   },
   "source": [
    "# Interfere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eVvMB_mcZtgS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 691
    },
    "id": "eVvMB_mcZtgS",
    "outputId": "cabe735e-906f-478f-e7a1-92b798717cfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 401104 entries, 0 to 401103\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   question_id   401104 non-null  object \n",
      " 1   text          401104 non-null  object \n",
      " 2   law_id        401104 non-null  object \n",
      " 3   article_id    401104 non-null  object \n",
      " 4   article_text  401104 non-null  object \n",
      " 5   relevant      401104 non-null  int64  \n",
      " 6   bm25_score    401104 non-null  float64\n",
      " 7   bm25_index    401104 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 24.5+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>text</th>\n",
       "      <th>law_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_text</th>\n",
       "      <th>relevant</th>\n",
       "      <th>bm25_score</th>\n",
       "      <th>bm25_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>8</td>\n",
       "      <td>Chương trình giáo dục\\n\\n1. Chương trình giáo ...</td>\n",
       "      <td>1</td>\n",
       "      <td>98.957036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>31</td>\n",
       "      <td>Chương trình giáo dục phổ thông\\n\\n1. Chương t...</td>\n",
       "      <td>0</td>\n",
       "      <td>75.948595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>72</td>\n",
       "      <td>Trình độ chuẩn được đào tạo của nhà giáo\\n\\n1....</td>\n",
       "      <td>0</td>\n",
       "      <td>75.287686</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>34</td>\n",
       "      <td>Xác nhận hoàn thành chương trình tiểu học, tru...</td>\n",
       "      <td>0</td>\n",
       "      <td>75.077637</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>25</td>\n",
       "      <td>Chương trình giáo dục mầm non\\n\\n1. Chương trì...</td>\n",
       "      <td>0</td>\n",
       "      <td>73.555320</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401099</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>45/2019/QH14</td>\n",
       "      <td>17</td>\n",
       "      <td>Hành vi người sử dụng lao động không được làm ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401100</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>45/2019/QH14</td>\n",
       "      <td>16</td>\n",
       "      <td>Nghĩa vụ cung cấp thông tin khi giao kết hợp đ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401101</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>45/2019/QH14</td>\n",
       "      <td>15</td>\n",
       "      <td>Nguyên tắc giao kết hợp đồng lao động\\n\\n1. Tự...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401102</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>45/2019/QH14</td>\n",
       "      <td>14</td>\n",
       "      <td>Hình thức hợp đồng lao động\\n\\n1. Hợp đồng lao...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401103</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>45/2019/QH14</td>\n",
       "      <td>8</td>\n",
       "      <td>Các hành vi bị nghiêm cấm trong lĩnh vực lao đ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401104 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_id  ... bm25_index\n",
       "0              q-8  ...          0\n",
       "1              q-8  ...          1\n",
       "2              q-8  ...          2\n",
       "3              q-8  ...          3\n",
       "4              q-8  ...          4\n",
       "...            ...  ...        ...\n",
       "401099       q-530  ...       2274\n",
       "401100       q-530  ...       2275\n",
       "401101       q-530  ...       2276\n",
       "401102       q-530  ...       2277\n",
       "401103       q-530  ...       2278\n",
       "\n",
       "[401104 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test = pd.read_csv('/content/drive/MyDrive/vn_law/outputs/bm25.csv')\n",
    "print(df_test.info())\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z79M6OHHaBJI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z79M6OHHaBJI",
    "outputId": "475d753b-e61c-4ad9-b2cf-6f977146b755"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176/176 [00:04<00:00, 43.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "top50 = pd.DataFrame()\n",
    "for q in tqdm.tqdm(df_test['question_id'].unique()):\n",
    "    scores = df_test[df_test['question_id']==q]\n",
    "    top50 = pd.concat([top50,scores[:50]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PtPNTkgIacm-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "PtPNTkgIacm-",
    "outputId": "069bebbd-a55c-4c26-aa88-ebc0f69e0d61"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>text</th>\n",
       "      <th>law_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_text</th>\n",
       "      <th>relevant</th>\n",
       "      <th>bm25_score</th>\n",
       "      <th>bm25_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>8</td>\n",
       "      <td>Chương trình giáo dục\\n\\n1. Chương trình giáo ...</td>\n",
       "      <td>1</td>\n",
       "      <td>98.957036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>31</td>\n",
       "      <td>Chương trình giáo dục phổ thông\\n\\n1. Chương t...</td>\n",
       "      <td>0</td>\n",
       "      <td>75.948595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>72</td>\n",
       "      <td>Trình độ chuẩn được đào tạo của nhà giáo\\n\\n1....</td>\n",
       "      <td>0</td>\n",
       "      <td>75.287686</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>34</td>\n",
       "      <td>Xác nhận hoàn thành chương trình tiểu học, tru...</td>\n",
       "      <td>0</td>\n",
       "      <td>75.077637</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>25</td>\n",
       "      <td>Chương trình giáo dục mầm non\\n\\n1. Chương trì...</td>\n",
       "      <td>0</td>\n",
       "      <td>73.555320</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398870</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>03/VBHN-VPQH</td>\n",
       "      <td>16</td>\n",
       "      <td>Người được miễn, giảm thời gian tập sự hành ng...</td>\n",
       "      <td>0</td>\n",
       "      <td>22.695020</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398871</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>20/2012/QH13</td>\n",
       "      <td>16</td>\n",
       "      <td>“ Người được miễn, giảm thời gian tập sự hành ...</td>\n",
       "      <td>0</td>\n",
       "      <td>22.657265</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398872</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>19/2013/TT-BTP</td>\n",
       "      <td>30</td>\n",
       "      <td>Xử lý vi phạm đối với thí sinh tham dự kiểm tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>22.427098</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398873</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>19/2013/TT-BTP</td>\n",
       "      <td>19</td>\n",
       "      <td>Trách nhiệm của Bộ Tư pháp\\n\\n1. Kiểm tra, tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>21.956534</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398874</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>21/2010/TT-BTP</td>\n",
       "      <td>2</td>\n",
       "      <td>Trách nhiệm giám sát việc tập sự hành nghề luậ...</td>\n",
       "      <td>0</td>\n",
       "      <td>21.862055</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8800 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_id  ... bm25_index\n",
       "0              q-8  ...          0\n",
       "1              q-8  ...          1\n",
       "2              q-8  ...          2\n",
       "3              q-8  ...          3\n",
       "4              q-8  ...          4\n",
       "...            ...  ...        ...\n",
       "398870       q-530  ...         45\n",
       "398871       q-530  ...         46\n",
       "398872       q-530  ...         47\n",
       "398873       q-530  ...         48\n",
       "398874       q-530  ...         49\n",
       "\n",
       "[8800 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isQoFIAzbiMD",
   "metadata": {
    "id": "isQoFIAzbiMD"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "test_sent_1  = top50.text.apply(lambda x: re.sub('\\n',' ',x)).values\n",
    "test_sent_2  = top50.article_text.apply(lambda x: re.sub('\\n',' ',x)).values\n",
    "# train_labels = df_train.label.apply(lambda x: 1 if x==True else 0).values\n",
    "test_labels = top50.relevant.values\n",
    "test_domains = le.transform(top50.law_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZztRxgm2bbyB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZztRxgm2bbyB",
    "outputId": "6d6fcf16-7782-4157-af04-e28e56302a29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8800, 70]),\n",
       " torch.Size([8800, 70]),\n",
       " torch.Size([8800, 70]),\n",
       " torch.Size([8800, 500]),\n",
       " torch.Size([8800, 500]),\n",
       " torch.Size([8800, 500]),\n",
       " torch.Size([8800]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_1 = []\n",
    "attention_masks_1 = []\n",
    "token_type_ids_1 = []\n",
    "input_ids_2 = []\n",
    "attention_masks_2 = []\n",
    "token_type_ids_2 = []\n",
    "\n",
    "for sent1, sent2 in zip(test_sent_1, test_sent_2):\n",
    "  encoded_dict = tokenizer.encode_plus( sent1, \n",
    "                                        add_special_tokens = True, \n",
    "                                        max_length = MAX_LENGTH_Q,         \n",
    "                                        padding = 'max_length',\n",
    "                                        return_attention_mask = True,   \n",
    "                                        return_token_type_ids = True,   \n",
    "                                        truncation = True,\n",
    "                                  )\n",
    "  input_ids_1.append(encoded_dict['input_ids'])\n",
    "  attention_masks_1.append(encoded_dict['attention_mask'])\n",
    "  token_type_ids_1.append(encoded_dict['token_type_ids'])\n",
    "\n",
    "  encoded_dict = tokenizer.encode_plus( sent2, \n",
    "                                        add_special_tokens = True, \n",
    "                                        max_length = MAX_LENGTH,         \n",
    "                                        padding = 'max_length',\n",
    "                                        return_attention_mask = True,   \n",
    "                                        return_token_type_ids = True,   \n",
    "                                        truncation = True,\n",
    "                                  )\n",
    "  input_ids_2.append(encoded_dict['input_ids'])\n",
    "  attention_masks_2.append(encoded_dict['attention_mask'])\n",
    "  token_type_ids_2.append(encoded_dict['token_type_ids'])\n",
    "\n",
    "\n",
    "test_input_ids_1 = torch.tensor(input_ids_1)\n",
    "test_attention_masks_1 = torch.tensor(attention_masks_1)\n",
    "test_token_type_ids_1 = torch.tensor(token_type_ids_1)\n",
    "test_input_ids_2 = torch.tensor(input_ids_2)\n",
    "test_attention_masks_2 = torch.tensor(attention_masks_2)\n",
    "test_token_type_ids_2 = torch.tensor(token_type_ids_2)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "test_domains = torch.tensor(test_domains)\n",
    "test_input_ids_1.size(), test_attention_masks_1.size(), test_token_type_ids_1.size(), test_input_ids_2.size(), test_attention_masks_2.size(), test_token_type_ids_2.size(), test_labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61UCHLZwbfFB",
   "metadata": {
    "id": "61UCHLZwbfFB"
   },
   "outputs": [],
   "source": [
    "test_data = TensorDataset(test_input_ids_1, test_attention_masks_1, test_token_type_ids_1, test_input_ids_2, test_attention_masks_2, test_token_type_ids_2, test_labels, test_domains)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9TFvrch6b-4s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9TFvrch6b-4s",
    "outputId": "d3e1c6ab-78bb-4fd3-a3ea-3b9cc7d4763d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type ibert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-810000 were not used when initializing Model: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Model were not initialized from the model checkpoint at /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-810000 and are newly initialized: ['lstm_sent_fw.bias', 'domain_layer.linear.bias', 'fc_layer.linear.weight', 'lstm_tar_fw.U', 'attention_tar.linear.weight', 'lstm_tar_bw.U', 'lstm_sent_bw.bias', 'attention_sent.linear.bias', 'lstm_sent_bw.W', 'bert.pooler.dense.weight', 'lstm_sent_fw.U', 'attention_layer.linear.weight', 'lstm_tar_bw.bias', 'lstm_tar_bw.W', 'fc_layer.linear.bias', 'out_layer.linear.bias', 'domain_layer.linear.weight', 'lstm_tar_fw.bias', 'lstm_sent_bw.U', 'attention_sent.linear.weight', 'bert.pooler.dense.bias', 'lstm_sent_fw.W', 'lstm_tar_fw.W', 'attention_tar.linear.bias', 'out_layer.linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "08/24/2021 09:15:01 - INFO - __main__ -   ***** Model Loaded *****\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(args, train_dataset=train_data, dev_dataset=test_data)\n",
    "trainer.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4kQxk4QUcDYK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4kQxk4QUcDYK",
    "outputId": "dca5f07c-d9a0-4383-ffaf-b32980131b5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/24/2021 09:15:01 - INFO - __main__ -   ***** Running evaluation on dev dataset *****\n",
      "08/24/2021 09:15:01 - INFO - __main__ -     Num examples = 8800\n",
      "08/24/2021 09:15:01 - INFO - __main__ -     Batch size = 8\n",
      "08/24/2021 09:15:01 - INFO - __main__ -   VAL: [0/1100] Elapsed 0m 0s (remain 9m 59s) Loss: 0.8845 Loss_rel: 0.7874 Loss_domain: 3.2393 \n",
      "08/24/2021 09:15:46 - INFO - __main__ -   VAL: [100/1100] Elapsed 0m 0s (remain 0m 4s) Loss: 0.2788 Loss_rel: 0.1916 Loss_domain: 2.9073 \n",
      "08/24/2021 09:16:32 - INFO - __main__ -   VAL: [200/1100] Elapsed 0m 0s (remain 0m 2s) Loss: 0.2932 Loss_rel: 0.2035 Loss_domain: 2.9902 \n",
      "08/24/2021 09:17:19 - INFO - __main__ -   VAL: [300/1100] Elapsed 0m 0s (remain 0m 1s) Loss: 0.2749 Loss_rel: 0.1825 Loss_domain: 3.0779 \n",
      "08/24/2021 09:18:08 - INFO - __main__ -   VAL: [400/1100] Elapsed 0m 0s (remain 0m 0s) Loss: 0.2794 Loss_rel: 0.1851 Loss_domain: 3.1430 \n",
      "08/24/2021 09:18:56 - INFO - __main__ -   VAL: [500/1100] Elapsed 0m 0s (remain 0m 0s) Loss: 0.2769 Loss_rel: 0.1815 Loss_domain: 3.1789 \n",
      "08/24/2021 09:19:44 - INFO - __main__ -   VAL: [600/1100] Elapsed 0m 0s (remain 0m 0s) Loss: 0.2809 Loss_rel: 0.1862 Loss_domain: 3.1554 \n",
      "08/24/2021 09:20:33 - INFO - __main__ -   VAL: [700/1100] Elapsed 0m 0s (remain 0m 0s) Loss: 0.2910 Loss_rel: 0.1964 Loss_domain: 3.1523 \n",
      "08/24/2021 09:21:22 - INFO - __main__ -   VAL: [800/1100] Elapsed 0m 0s (remain 0m 0s) Loss: 0.2939 Loss_rel: 0.1995 Loss_domain: 3.1453 \n",
      "08/24/2021 09:22:11 - INFO - __main__ -   VAL: [900/1100] Elapsed 0m 0s (remain 0m 0s) Loss: 0.2964 Loss_rel: 0.2022 Loss_domain: 3.1413 \n",
      "08/24/2021 09:23:00 - INFO - __main__ -   VAL: [1000/1100] Elapsed 0m 0s (remain 0m 0s) Loss: 0.2983 Loss_rel: 0.2048 Loss_domain: 3.1174 \n",
      "08/24/2021 09:23:48 - INFO - __main__ -   VAL: [1099/1100] Elapsed 0m 0s (remain 0m 0s) Loss: 0.2995 Loss_rel: 0.2050 Loss_domain: 3.1493 \n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "08/24/2021 09:23:48 - INFO - __main__ -   ***** Eval results *****\n",
      "08/24/2021 09:23:48 - INFO - __main__ -     acc = 0.8642\n",
      "08/24/2021 09:23:48 - INFO - __main__ -     f2_macro = 0.0839\n",
      "08/24/2021 09:23:48 - INFO - __main__ -     loss = 0.2995\n",
      "08/24/2021 09:23:48 - INFO - __main__ -     p_none = 0.9891\n",
      "08/24/2021 09:23:48 - INFO - __main__ -     p_rel = 0.0772\n",
      "08/24/2021 09:23:48 - INFO - __main__ -     r_none = 0.8711\n",
      "08/24/2021 09:23:48 - INFO - __main__ -     r_rel = 0.5284\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.evaluate(\"dev\", out_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QLUO96nHeS-R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "QLUO96nHeS-R",
    "outputId": "0ac8b6b4-0a83-419f-e255-4041ab766ab8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>text</th>\n",
       "      <th>law_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_text</th>\n",
       "      <th>relevant</th>\n",
       "      <th>bm25_score</th>\n",
       "      <th>bm25_index</th>\n",
       "      <th>bert_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>8</td>\n",
       "      <td>Chương trình giáo dục\\n\\n1. Chương trình giáo ...</td>\n",
       "      <td>1</td>\n",
       "      <td>98.957036</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>31</td>\n",
       "      <td>Chương trình giáo dục phổ thông\\n\\n1. Chương t...</td>\n",
       "      <td>0</td>\n",
       "      <td>75.948595</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>72</td>\n",
       "      <td>Trình độ chuẩn được đào tạo của nhà giáo\\n\\n1....</td>\n",
       "      <td>0</td>\n",
       "      <td>75.287686</td>\n",
       "      <td>2</td>\n",
       "      <td>0.056909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>34</td>\n",
       "      <td>Xác nhận hoàn thành chương trình tiểu học, tru...</td>\n",
       "      <td>0</td>\n",
       "      <td>75.077637</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>25</td>\n",
       "      <td>Chương trình giáo dục mầm non\\n\\n1. Chương trì...</td>\n",
       "      <td>0</td>\n",
       "      <td>73.555320</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398870</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>03/VBHN-VPQH</td>\n",
       "      <td>16</td>\n",
       "      <td>Người được miễn, giảm thời gian tập sự hành ng...</td>\n",
       "      <td>0</td>\n",
       "      <td>22.695020</td>\n",
       "      <td>45</td>\n",
       "      <td>0.010078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398871</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>20/2012/QH13</td>\n",
       "      <td>16</td>\n",
       "      <td>“ Người được miễn, giảm thời gian tập sự hành ...</td>\n",
       "      <td>0</td>\n",
       "      <td>22.657265</td>\n",
       "      <td>46</td>\n",
       "      <td>0.008798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398872</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>19/2013/TT-BTP</td>\n",
       "      <td>30</td>\n",
       "      <td>Xử lý vi phạm đối với thí sinh tham dự kiểm tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>22.427098</td>\n",
       "      <td>47</td>\n",
       "      <td>0.005407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398873</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>19/2013/TT-BTP</td>\n",
       "      <td>19</td>\n",
       "      <td>Trách nhiệm của Bộ Tư pháp\\n\\n1. Kiểm tra, tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>21.956534</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398874</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>21/2010/TT-BTP</td>\n",
       "      <td>2</td>\n",
       "      <td>Trách nhiệm giám sát việc tập sự hành nghề luậ...</td>\n",
       "      <td>0</td>\n",
       "      <td>21.862055</td>\n",
       "      <td>49</td>\n",
       "      <td>0.001917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8800 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_id  ... bert_model\n",
       "0              q-8  ...   0.002352\n",
       "1              q-8  ...   0.001196\n",
       "2              q-8  ...   0.056909\n",
       "3              q-8  ...   0.001930\n",
       "4              q-8  ...   0.001281\n",
       "...            ...  ...        ...\n",
       "398870       q-530  ...   0.010078\n",
       "398871       q-530  ...   0.008798\n",
       "398872       q-530  ...   0.005407\n",
       "398873       q-530  ...   0.001055\n",
       "398874       q-530  ...   0.001917\n",
       "\n",
       "[8800 rows x 9 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50['bert_model'] = preds\n",
    "top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cx-NIEA2jjw8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cx-NIEA2jjw8",
    "outputId": "8c0f188a-b6e2-4c55-8a0a-0065d24db069"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176/176 [00:00<00:00, 622.82it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "final_csv = pd.DataFrame()\n",
    "final_json = []\n",
    "id = []\n",
    "text = []\n",
    "law_id = []\n",
    "article_id = []\n",
    "article_text = []\n",
    "bm25_score = []\n",
    "bm25_index = []\n",
    "bert_model = []\n",
    "en_score = []\n",
    "for q in tqdm.tqdm(df_test['question_id'].unique()):\n",
    "    scores = top50[top50['question_id']==q]\n",
    "    bm25_scores = scores['bm25_score'].values\n",
    "    model_scores = scores['bert_model'].values\n",
    "    bm25_scores = bm25_scores.reshape(-1,1)\n",
    "    model_scores = model_scores.reshape(-1,1)\n",
    "    # print(bm25_scores)\n",
    "    scaler = MinMaxScaler()\n",
    "    bm25_scores = scaler.fit_transform(bm25_scores)\n",
    "    model_scores = scaler.fit_transform(model_scores)\n",
    "    # print(bm25_scores)\n",
    "    threshold = 0.95\n",
    "    final = threshold*bm25_scores + (1-threshold)*model_scores\n",
    "    info = scores.iloc[final.argmax()]\n",
    "\n",
    "    id.append(info['question_id'])\n",
    "    text.append(info['text'])\n",
    "    law_id.append(info['law_id'])\n",
    "    article_id.append(info['article_id'])\n",
    "    article_text.append(info['article_text'])\n",
    "    bm25_score.append(info['bm25_score'])\n",
    "    bm25_index.append(info['bm25_index'])\n",
    "    bert_model.append(info['bert_model'])\n",
    "    en_score.append(final.max())\n",
    "\n",
    "    ans = {}\n",
    "    ans['question_id'] = info['question_id']\n",
    "    ans['relevant_articles'] = []\n",
    "    for index in range(1):\n",
    "        rel_article = {}\n",
    "        rel_article['law_id'] = info['law_id']\n",
    "        rel_article['article_id'] = info['article_id']\n",
    "        ans['relevant_articles'].append(rel_article)\n",
    "    final_json.append(ans)\n",
    "    # print(final_json)\n",
    "    # break\n",
    "\n",
    "final_csv['question_id'] = id \n",
    "final_csv['text'] = text \n",
    "final_csv['law_id'] = law_id \n",
    "final_csv['article_id'] = article_id\n",
    "final_csv['article_text'] = article_text\n",
    "final_csv['bm25_score'] =bm25_score\n",
    "final_csv['bm25_index'] =bm25_index\n",
    "final_csv['bert_model'] =bert_model\n",
    "final_csv['en_score'] = en_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VOQtwgaQrqb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "VOQtwgaQrqb3",
    "outputId": "607f6c04-5b47-4a3b-8610-645e4484115d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>text</th>\n",
       "      <th>law_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_text</th>\n",
       "      <th>bm25_score</th>\n",
       "      <th>bm25_index</th>\n",
       "      <th>bert_model</th>\n",
       "      <th>en_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q-8</td>\n",
       "      <td>Chuẩn kiến thức, kỹ năng, yêu cầu cần đạt về p...</td>\n",
       "      <td>43/2019/QH14</td>\n",
       "      <td>8</td>\n",
       "      <td>Chương trình giáo dục\\n\\n1. Chương trình giáo ...</td>\n",
       "      <td>98.957036</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.950062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q-113</td>\n",
       "      <td>Ủy ban nhân dân có quyền tuyên bố hợp đồng lao...</td>\n",
       "      <td>45/2019/QH14</td>\n",
       "      <td>50</td>\n",
       "      <td>Thẩm quyền tuyên bố hợp đồng lao động vô hiệu\\...</td>\n",
       "      <td>31.295999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504207</td>\n",
       "      <td>0.976334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q-193</td>\n",
       "      <td>Sử dụng bảo vật quốc gia với mục đích trái phé...</td>\n",
       "      <td>100/2015/QH13</td>\n",
       "      <td>177</td>\n",
       "      <td>Tội sử dụng trái phép tài sản\\n\\n1. Người nào ...</td>\n",
       "      <td>29.865201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>0.950416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q-539</td>\n",
       "      <td>Chứng chỉ hành nghề luật sư bị thu hồi khi khô...</td>\n",
       "      <td>65/2006/QH11</td>\n",
       "      <td>18</td>\n",
       "      <td>Thu hồi Chứng chỉ hành nghề luật sư\\n\\n1. Ngườ...</td>\n",
       "      <td>31.338341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.950035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q-48</td>\n",
       "      <td>Nơi cư trú của công dân có thể là nơi tạm trú.</td>\n",
       "      <td>68/2020/QH14</td>\n",
       "      <td>11</td>\n",
       "      <td>Nơi cư trú của công dân\\n\\n1. Nơi cư trú của c...</td>\n",
       "      <td>34.313530</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503403</td>\n",
       "      <td>0.975748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>q-364</td>\n",
       "      <td>Bộ Tài nguyên và Môi trường chịu trách nhiệm t...</td>\n",
       "      <td>45/2013/QH13</td>\n",
       "      <td>23</td>\n",
       "      <td>Trách nhiệm quản lý nhà nước về đất đai\\n\\n1. ...</td>\n",
       "      <td>53.337361</td>\n",
       "      <td>0</td>\n",
       "      <td>0.451064</td>\n",
       "      <td>0.973028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>q-477</td>\n",
       "      <td>Báo cáo quá trình tập sự hành nghề luật sư của...</td>\n",
       "      <td>19/2013/TT-BTP</td>\n",
       "      <td>11</td>\n",
       "      <td>Báo cáo quá trình tập sự hành nghề luật sư\\n\\n...</td>\n",
       "      <td>81.761348</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918821</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>q-487</td>\n",
       "      <td>Luật sư hướng dẫn tập sự hành nghề luật sư có ...</td>\n",
       "      <td>19/2013/TT-BTP</td>\n",
       "      <td>12</td>\n",
       "      <td>Điều kiện đối với luật sư hướng dẫn\\n\\nLuật sư...</td>\n",
       "      <td>57.510731</td>\n",
       "      <td>0</td>\n",
       "      <td>0.946033</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>q-274</td>\n",
       "      <td>Tài sản được giao theo phương thức do các bên ...</td>\n",
       "      <td>91/2015/QH13</td>\n",
       "      <td>436</td>\n",
       "      <td>Phương thức giao tài sản\\n\\n1. Tài sản được gi...</td>\n",
       "      <td>82.338358</td>\n",
       "      <td>0</td>\n",
       "      <td>0.910167</td>\n",
       "      <td>0.997023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>q-530</td>\n",
       "      <td>Thẩm quyền tổ chức kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>21/2010/TT-BTP</td>\n",
       "      <td>23</td>\n",
       "      <td>Thành lập Hội đồng kiểm tra kết quả tập sự hàn...</td>\n",
       "      <td>48.879835</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>0.950216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_id  ...  en_score\n",
       "0           q-8  ...  0.950062\n",
       "1         q-113  ...  0.976334\n",
       "2         q-193  ...  0.950416\n",
       "3         q-539  ...  0.950035\n",
       "4          q-48  ...  0.975748\n",
       "..          ...  ...       ...\n",
       "171       q-364  ...  0.973028\n",
       "172       q-477  ...  1.000000\n",
       "173       q-487  ...  1.000000\n",
       "174       q-274  ...  0.997023\n",
       "175       q-530  ...  0.950216\n",
       "\n",
       "[176 rows x 9 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RxG5SlSJtCmg",
   "metadata": {
    "id": "RxG5SlSJtCmg"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/content/drive/MyDrive/vn_law/outputs/output_bm25_bert_domain.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_json, f, indent=4, ensure_ascii=False)\n",
    "final_csv.to_csv('/content/drive/MyDrive/vn_law/outputs/bm25_bert_domain.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NH93UzSQtuSa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NH93UzSQtuSa",
    "outputId": "b533c9d1-de24-4176-9a5b-0fd2555fb5f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question_id': 'q-8',\n",
       "  'relevant_articles': [{'article_id': '2', 'law_id': '123/2013/NĐ-CP'}]},\n",
       " {'question_id': 'q-113',\n",
       "  'relevant_articles': [{'article_id': '66', 'law_id': '45/2013/QH13'}]},\n",
       " {'question_id': 'q-193',\n",
       "  'relevant_articles': [{'article_id': '293', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-539',\n",
       "  'relevant_articles': [{'article_id': '17', 'law_id': '137/2018/NĐ-CP'}]},\n",
       " {'question_id': 'q-48',\n",
       "  'relevant_articles': [{'article_id': '5', 'law_id': '68/2020/QH14'}]},\n",
       " {'question_id': 'q-23',\n",
       "  'relevant_articles': [{'article_id': '14', 'law_id': '43/2019/QH14'}]},\n",
       " {'question_id': 'q-217',\n",
       "  'relevant_articles': [{'article_id': '127', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-183',\n",
       "  'relevant_articles': [{'article_id': '138', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-423',\n",
       "  'relevant_articles': [{'article_id': '17', 'law_id': '137/2018/NĐ-CP'}]},\n",
       " {'question_id': 'q-133',\n",
       "  'relevant_articles': [{'article_id': '106', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-110',\n",
       "  'relevant_articles': [{'article_id': '26', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-535',\n",
       "  'relevant_articles': [{'article_id': '15', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-92',\n",
       "  'relevant_articles': [{'article_id': '33', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-192',\n",
       "  'relevant_articles': [{'article_id': '293', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-408',\n",
       "  'relevant_articles': [{'article_id': '11', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-168',\n",
       "  'relevant_articles': [{'article_id': '90', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-533',\n",
       "  'relevant_articles': [{'article_id': '15', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-55',\n",
       "  'relevant_articles': [{'article_id': '22', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-76',\n",
       "  'relevant_articles': [{'article_id': '9', 'law_id': '68/2020/QH14'}]},\n",
       " {'question_id': 'q-292',\n",
       "  'relevant_articles': [{'article_id': '658', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-421',\n",
       "  'relevant_articles': [{'article_id': '17', 'law_id': '137/2018/NĐ-CP'}]},\n",
       " {'question_id': 'q-374',\n",
       "  'relevant_articles': [{'article_id': '25', 'law_id': '45/2013/QH13'}]},\n",
       " {'question_id': 'q-378',\n",
       "  'relevant_articles': [{'article_id': '47', 'law_id': '45/2013/QH13'}]},\n",
       " {'question_id': 'q-263',\n",
       "  'relevant_articles': [{'article_id': '257', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-63',\n",
       "  'relevant_articles': [{'article_id': '35', 'law_id': '68/2020/QH14'}]},\n",
       " {'question_id': 'q-171',\n",
       "  'relevant_articles': [{'article_id': '9', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-432',\n",
       "  'relevant_articles': [{'article_id': '21', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-422',\n",
       "  'relevant_articles': [{'article_id': '17', 'law_id': '137/2018/NĐ-CP'}]},\n",
       " {'question_id': 'q-307',\n",
       "  'relevant_articles': [{'article_id': '611', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-240',\n",
       "  'relevant_articles': [{'article_id': '3', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-339',\n",
       "  'relevant_articles': [{'article_id': '65', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-459',\n",
       "  'relevant_articles': [{'article_id': '21', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-490',\n",
       "  'relevant_articles': [{'article_id': '12', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-564',\n",
       "  'relevant_articles': [{'article_id': '4', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-396',\n",
       "  'relevant_articles': [{'article_id': '4', 'law_id': '65/2006/QH11'}]},\n",
       " {'question_id': 'q-402',\n",
       "  'relevant_articles': [{'article_id': '9', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-158',\n",
       "  'relevant_articles': [{'article_id': '156', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-519',\n",
       "  'relevant_articles': [{'article_id': '12', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-261',\n",
       "  'relevant_articles': [{'article_id': '254', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-540',\n",
       "  'relevant_articles': [{'article_id': '17', 'law_id': '137/2018/NĐ-CP'}]},\n",
       " {'question_id': 'q-126',\n",
       "  'relevant_articles': [{'article_id': '187', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-567',\n",
       "  'relevant_articles': [{'article_id': '14', 'law_id': '123/2013/NĐ-CP'}]},\n",
       " {'question_id': 'q-568',\n",
       "  'relevant_articles': [{'article_id': '14', 'law_id': '123/2013/NĐ-CP'}]},\n",
       " {'question_id': 'q-98',\n",
       "  'relevant_articles': [{'article_id': '26', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-427',\n",
       "  'relevant_articles': [{'article_id': '14', 'law_id': '123/2013/NĐ-CP'}]},\n",
       " {'question_id': 'q-112',\n",
       "  'relevant_articles': [{'article_id': '33', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-285',\n",
       "  'relevant_articles': [{'article_id': '612', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-371',\n",
       "  'relevant_articles': [{'article_id': '30', 'law_id': '45/2013/QH13'}]},\n",
       " {'question_id': 'q-504',\n",
       "  'relevant_articles': [{'article_id': '4', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-236',\n",
       "  'relevant_articles': [{'article_id': '8', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-499',\n",
       "  'relevant_articles': [{'article_id': '11', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-486',\n",
       "  'relevant_articles': [{'article_id': '12', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-131',\n",
       "  'relevant_articles': [{'article_id': '90', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-403',\n",
       "  'relevant_articles': [{'article_id': '2', 'law_id': '11/2017/QH14'}]},\n",
       " {'question_id': 'q-311',\n",
       "  'relevant_articles': [{'article_id': '65', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-250',\n",
       "  'relevant_articles': [{'article_id': '118', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-56',\n",
       "  'relevant_articles': [{'article_id': '22', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-383',\n",
       "  'relevant_articles': [{'article_id': '47', 'law_id': '45/2013/QH13'}]},\n",
       " {'question_id': 'q-387',\n",
       "  'relevant_articles': [{'article_id': '159', 'law_id': '45/2013/QH13'}]},\n",
       " {'question_id': 'q-534',\n",
       "  'relevant_articles': [{'article_id': '15', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-575',\n",
       "  'relevant_articles': [{'article_id': '32', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-18',\n",
       "  'relevant_articles': [{'article_id': '16', 'law_id': '43/2019/QH14'}]},\n",
       " {'question_id': 'q-354',\n",
       "  'relevant_articles': [{'article_id': '2', 'law_id': '45/2013/QH13'}]},\n",
       " {'question_id': 'q-503',\n",
       "  'relevant_articles': [{'article_id': '4', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-397',\n",
       "  'relevant_articles': [{'article_id': '21', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-40',\n",
       "  'relevant_articles': [{'article_id': '75', 'law_id': '43/2019/QH14'}]},\n",
       " {'question_id': 'q-30',\n",
       "  'relevant_articles': [{'article_id': '37', 'law_id': '43/2019/QH14'}]},\n",
       " {'question_id': 'q-585',\n",
       "  'relevant_articles': [{'article_id': '21', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-393',\n",
       "  'relevant_articles': [{'article_id': '66', 'law_id': '45/2013/QH13'}]},\n",
       " {'question_id': 'q-537',\n",
       "  'relevant_articles': [{'article_id': '15', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-303',\n",
       "  'relevant_articles': [{'article_id': '41', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-410',\n",
       "  'relevant_articles': [{'article_id': '17', 'law_id': '137/2018/NĐ-CP'}]},\n",
       " {'question_id': 'q-68',\n",
       "  'relevant_articles': [{'article_id': '23', 'law_id': '68/2020/QH14'}]},\n",
       " {'question_id': 'q-246',\n",
       "  'relevant_articles': [{'article_id': '105', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-146',\n",
       "  'relevant_articles': [{'article_id': '22', 'law_id': '43/2019/QH14'}]},\n",
       " {'question_id': 'q-536',\n",
       "  'relevant_articles': [{'article_id': '15', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-188',\n",
       "  'relevant_articles': [{'article_id': '257', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-470',\n",
       "  'relevant_articles': [{'article_id': '11', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-478',\n",
       "  'relevant_articles': [{'article_id': '12', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-234',\n",
       "  'relevant_articles': [{'article_id': '17', 'law_id': '137/2018/NĐ-CP'}]},\n",
       " {'question_id': 'q-553',\n",
       "  'relevant_articles': [{'article_id': '9', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-430',\n",
       "  'relevant_articles': [{'article_id': '21', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-394',\n",
       "  'relevant_articles': [{'article_id': '21', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-352',\n",
       "  'relevant_articles': [{'article_id': '12', 'law_id': '68/2020/QH14'}]},\n",
       " {'question_id': 'q-106',\n",
       "  'relevant_articles': [{'article_id': '300', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-71',\n",
       "  'relevant_articles': [{'article_id': '11', 'law_id': '68/2020/QH14'}]},\n",
       " {'question_id': 'q-291',\n",
       "  'relevant_articles': [{'article_id': '612', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-170',\n",
       "  'relevant_articles': [{'article_id': '9', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-425',\n",
       "  'relevant_articles': [{'article_id': '14', 'law_id': '123/2013/NĐ-CP'}]},\n",
       " {'question_id': 'q-182',\n",
       "  'relevant_articles': [{'article_id': '62', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-466',\n",
       "  'relevant_articles': [{'article_id': '4', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-299',\n",
       "  'relevant_articles': [{'article_id': '628', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-141',\n",
       "  'relevant_articles': [{'article_id': '90', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-347',\n",
       "  'relevant_articles': [{'article_id': '136', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-444',\n",
       "  'relevant_articles': [{'article_id': '17', 'law_id': '137/2018/NĐ-CP'}]},\n",
       " {'question_id': 'q-99',\n",
       "  'relevant_articles': [{'article_id': '129', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-73',\n",
       "  'relevant_articles': [{'article_id': '5', 'law_id': '68/2020/QH14'}]},\n",
       " {'question_id': 'q-317',\n",
       "  'relevant_articles': [{'article_id': '74', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-367',\n",
       "  'relevant_articles': [{'article_id': '2', 'law_id': '45/2013/QH13'}]},\n",
       " {'question_id': 'q-216',\n",
       "  'relevant_articles': [{'article_id': '293', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-300',\n",
       "  'relevant_articles': [{'article_id': '628', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-5',\n",
       "  'relevant_articles': [{'article_id': '7', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-528',\n",
       "  'relevant_articles': [{'article_id': '15', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-583',\n",
       "  'relevant_articles': [{'article_id': '12', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-101',\n",
       "  'relevant_articles': [{'article_id': '90', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-301',\n",
       "  'relevant_articles': [{'article_id': '8', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-566',\n",
       "  'relevant_articles': [{'article_id': '4', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-58',\n",
       "  'relevant_articles': [{'article_id': '20', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-74',\n",
       "  'relevant_articles': [{'article_id': '5', 'law_id': '68/2020/QH14'}]},\n",
       " {'question_id': 'q-95',\n",
       "  'relevant_articles': [{'article_id': '26', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-586',\n",
       "  'relevant_articles': [{'article_id': '21', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-191',\n",
       "  'relevant_articles': [{'article_id': '402', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-372',\n",
       "  'relevant_articles': [{'article_id': '30', 'law_id': '45/2013/QH13'}]},\n",
       " {'question_id': 'q-255',\n",
       "  'relevant_articles': [{'article_id': '65', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-556',\n",
       "  'relevant_articles': [{'article_id': '25', 'law_id': '65/2006/QH11'}]},\n",
       " {'question_id': 'q-4',\n",
       "  'relevant_articles': [{'article_id': '11', 'law_id': '43/2019/QH14'}]},\n",
       " {'question_id': 'q-181',\n",
       "  'relevant_articles': [{'article_id': '62', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-343',\n",
       "  'relevant_articles': [{'article_id': '22', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-336',\n",
       "  'relevant_articles': [{'article_id': '9', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-93',\n",
       "  'relevant_articles': [{'article_id': '3', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-114',\n",
       "  'relevant_articles': [{'article_id': '102', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-345',\n",
       "  'relevant_articles': [{'article_id': '65', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-89',\n",
       "  'relevant_articles': [{'article_id': '102', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-66',\n",
       "  'relevant_articles': [{'article_id': '62', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-1',\n",
       "  'relevant_articles': [{'article_id': '16', 'law_id': '43/2019/QH14'}]},\n",
       " {'question_id': 'q-143',\n",
       "  'relevant_articles': [{'article_id': '60', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-590',\n",
       "  'relevant_articles': [{'article_id': '12', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-516',\n",
       "  'relevant_articles': [{'article_id': '12', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-50',\n",
       "  'relevant_articles': [{'article_id': '136', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-464',\n",
       "  'relevant_articles': [{'article_id': '11', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-337',\n",
       "  'relevant_articles': [{'article_id': '65', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-222',\n",
       "  'relevant_articles': [{'article_id': '289', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-365',\n",
       "  'relevant_articles': [{'article_id': '25', 'law_id': '45/2013/QH13'}]},\n",
       " {'question_id': 'q-37',\n",
       "  'relevant_articles': [{'article_id': '75', 'law_id': '43/2019/QH14'}]},\n",
       " {'question_id': 'q-122',\n",
       "  'relevant_articles': [{'article_id': '33', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-174',\n",
       "  'relevant_articles': [{'article_id': '9', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-120',\n",
       "  'relevant_articles': [{'article_id': '71', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-151',\n",
       "  'relevant_articles': [{'article_id': '8', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-137',\n",
       "  'relevant_articles': [{'article_id': '102', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-489',\n",
       "  'relevant_articles': [{'article_id': '12', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-351',\n",
       "  'relevant_articles': [{'article_id': '22', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-570',\n",
       "  'relevant_articles': [{'article_id': '14', 'law_id': '123/2013/NĐ-CP'}]},\n",
       " {'question_id': 'q-524',\n",
       "  'relevant_articles': [{'article_id': '15', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-384',\n",
       "  'relevant_articles': [{'article_id': '66', 'law_id': '45/2013/QH13'}]},\n",
       " {'question_id': 'q-256',\n",
       "  'relevant_articles': [{'article_id': '257', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-482',\n",
       "  'relevant_articles': [{'article_id': '12', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-515',\n",
       "  'relevant_articles': [{'article_id': '4', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-162',\n",
       "  'relevant_articles': [{'article_id': '18', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-194',\n",
       "  'relevant_articles': [{'article_id': '62', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-79',\n",
       "  'relevant_articles': [{'article_id': '5', 'law_id': '68/2020/QH14'}]},\n",
       " {'question_id': 'q-257',\n",
       "  'relevant_articles': [{'article_id': '430', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-57',\n",
       "  'relevant_articles': [{'article_id': '20', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-319',\n",
       "  'relevant_articles': [{'article_id': '7', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-127',\n",
       "  'relevant_articles': [{'article_id': '33', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-52',\n",
       "  'relevant_articles': [{'article_id': '136', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-219',\n",
       "  'relevant_articles': [{'article_id': '257', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-265',\n",
       "  'relevant_articles': [{'article_id': '257', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-579',\n",
       "  'relevant_articles': [{'article_id': '2', 'law_id': '123/2013/NĐ-CP'}]},\n",
       " {'question_id': 'q-13',\n",
       "  'relevant_articles': [{'article_id': '37', 'law_id': '43/2019/QH14'}]},\n",
       " {'question_id': 'q-227',\n",
       "  'relevant_articles': [{'article_id': '402', 'law_id': '100/2015/QH13'}]},\n",
       " {'question_id': 'q-529',\n",
       "  'relevant_articles': [{'article_id': '15', 'law_id': '03/VBHN-VPQH'}]},\n",
       " {'question_id': 'q-94',\n",
       "  'relevant_articles': [{'article_id': '400', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-582',\n",
       "  'relevant_articles': [{'article_id': '12', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-335',\n",
       "  'relevant_articles': [{'article_id': '14', 'law_id': '68/2020/QH14'}]},\n",
       " {'question_id': 'q-326',\n",
       "  'relevant_articles': [{'article_id': '20', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-571',\n",
       "  'relevant_articles': [{'article_id': '14', 'law_id': '123/2013/NĐ-CP'}]},\n",
       " {'question_id': 'q-314',\n",
       "  'relevant_articles': [{'article_id': '8', 'law_id': '52/2014/QH13'}]},\n",
       " {'question_id': 'q-520',\n",
       "  'relevant_articles': [{'article_id': '12', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-123',\n",
       "  'relevant_articles': [{'article_id': '15', 'law_id': '45/2019/QH14'}]},\n",
       " {'question_id': 'q-441',\n",
       "  'relevant_articles': [{'article_id': '17', 'law_id': '137/2018/NĐ-CP'}]},\n",
       " {'question_id': 'q-426',\n",
       "  'relevant_articles': [{'article_id': '14', 'law_id': '123/2013/NĐ-CP'}]},\n",
       " {'question_id': 'q-364',\n",
       "  'relevant_articles': [{'article_id': '4', 'law_id': '45/2013/QH13'}]},\n",
       " {'question_id': 'q-477',\n",
       "  'relevant_articles': [{'article_id': '11', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-487',\n",
       "  'relevant_articles': [{'article_id': '12', 'law_id': '19/2013/TT-BTP'}]},\n",
       " {'question_id': 'q-274',\n",
       "  'relevant_articles': [{'article_id': '449', 'law_id': '91/2015/QH13'}]},\n",
       " {'question_id': 'q-530',\n",
       "  'relevant_articles': [{'article_id': '15', 'law_id': '03/VBHN-VPQH'}]}]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ix0uNehDrqil",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ix0uNehDrqil",
    "outputId": "5470ab0a-0984-4e47-f255-d06457578832"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question_id', 'text', 'law_id', 'article_id', 'article_text',\n",
       "       'relevant', 'bm25_score', 'bm25_index', 'bert_model'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gYU2RgZmkZ5z",
   "metadata": {
    "id": "gYU2RgZmkZ5z"
   },
   "outputs": [],
   "source": [
    "df_val['relevant'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ZxqBAYPkZ5z",
   "metadata": {
    "id": "5ZxqBAYPkZ5z"
   },
   "outputs": [],
   "source": [
    "#BERT\n",
    "08/20/2021 17:24:53 - INFO - __main__ -     acc = 0.7067\n",
    "08/20/2021 17:24:53 - INFO - __main__ -     f2_macro = 0.5643\n",
    "08/20/2021 17:24:53 - INFO - __main__ -     loss = 0.2703\n",
    "08/20/2021 17:24:53 - INFO - __main__ -     p_none = 0.9632\n",
    "08/20/2021 17:24:53 - INFO - __main__ -     p_rel = 0.2249\n",
    "08/20/2021 17:24:53 - INFO - __main__ -     r_none = 0.7001\n",
    "08/20/2021 17:24:53 - INFO - __main__ -     r_rel = 0.7647\n",
    "\n",
    "#BERT, domain\n",
    "08/20/2021 17:46:19 - INFO - __main__ -   ***** Eval results *****\n",
    "08/20/2021 17:46:19 - INFO - __main__ -     acc = 0.7885\n",
    "08/20/2021 17:46:19 - INFO - __main__ -     f2_macro = 0.6128\n",
    "08/20/2021 17:46:19 - INFO - __main__ -     loss = 0.2838\n",
    "08/20/2021 17:46:19 - INFO - __main__ -     p_none = 0.9673\n",
    "08/20/2021 17:46:19 - INFO - __main__ -     p_rel = 0.2941\n",
    "08/20/2021 17:46:19 - INFO - __main__ -     r_none = 0.7912\n",
    "08/20/2021 17:46:19 - INFO - __main__ -     r_rel = 0.7647\n",
    "\n",
    "#newBERT, domain\n",
    "08/22/2021 15:36:08 - INFO - __main__ -   ***** Eval results *****\n",
    "08/22/2021 15:36:08 - INFO - __main__ -     acc = 0.8570\n",
    "08/22/2021 15:36:08 - INFO - __main__ -     f2_macro = 0.6114\n",
    "08/22/2021 15:36:08 - INFO - __main__ -     loss = 0.4314\n",
    "08/22/2021 15:36:08 - INFO - __main__ -     p_none = 0.9631\n",
    "08/22/2021 15:36:08 - INFO - __main__ -     p_rel = 0.3896\n",
    "08/22/2021 15:36:08 - INFO - __main__ -     r_none = 0.8742\n",
    "08/22/2021 15:36:08 - INFO - __main__ -     r_rel = 0.7059\n",
    "08/22/2021 15:36:08 - INFO - __main__ -   Training total loss = 0.3205\n",
    "\n",
    "#newBert, domain, lstm\n",
    "08/22/2021 17:16:16 - INFO - __main__ -     acc = 0.8606\n",
    "08/22/2021 17:16:16 - INFO - __main__ -     f2_macro = 0.6380\n",
    "08/22/2021 17:16:16 - INFO - __main__ -     loss = 0.3957\n",
    "08/22/2021 17:16:16 - INFO - __main__ -     p_none = 0.9660\n",
    "08/22/2021 17:16:16 - INFO - __main__ -     p_rel = 0.4000\n",
    "08/22/2021 17:16:16 - INFO - __main__ -     r_none = 0.8755\n",
    "08/22/2021 17:16:16 - INFO - __main__ -     r_rel = 0.7294\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xG3v1ba2hViH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xG3v1ba2hViH",
    "outputId": "2a179741-3a1f-4535-ba23-025e67d8d06a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /content/transformers\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting huggingface-hub>=0.0.12\n",
      "  Downloading huggingface_hub-0.0.15-py3-none-any.whl (43 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (4.6.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (21.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (3.0.12)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (4.62.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers==4.10.0.dev0) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.10.0.dev0) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.0.dev0) (3.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (2.10)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0.dev0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0.dev0) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0.dev0) (1.15.0)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517): started\n",
      "  Building wheel for transformers (PEP 517): finished with status 'done'\n",
      "  Created wheel for transformers: filename=transformers-4.10.0.dev0-py3-none-any.whl size=2667071 sha256=0c2cd3041e4631d5cc909fb18178d8f8d1823b7b24e9a19d440250b08d2ad60a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-q84veem2/wheels/49/62/f4/6730819eed4e6468662b1519bf3bf46419b2335990c77f8767\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.0.15 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'transformers'...\n",
      "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git clone https://github.com/huggingface/transformers\n",
    "cd transformers\n",
    "pip install .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aBq9ccbcGKy",
   "metadata": {
    "id": "4aBq9ccbcGKy"
   },
   "outputs": [],
   "source": [
    "python3 run_mlm.py \\\n",
    "    --model_name_or_path NlpHUST/vibert4news-base-cased \\\n",
    "    --train_file /content/drive/MyDrive/vn_law/law.vi.txt \\\n",
    "    --validation_file /content/drive/MyDrive/vn_law/law.vi.small.txt \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --line_by_line \\\n",
    "    --validation_split_percentage 5 \\\n",
    "    --per_device_train_batch_size 8 \\\n",
    "    --per_device_eval_batch_size 8 \\\n",
    "    --num_train_epochs 10 \\\n",
    "    --max_seq_length 512 \\\n",
    "    --logging_steps=5000 \\\n",
    "    --save_steps=5000 \\\n",
    "    --eval_steps=5000 \\\n",
    "    --evaluation_strategy steps \\\n",
    "    --output_dir /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3yUH6jf40__k",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3yUH6jf40__k",
    "outputId": "02758aad-ed97-48ea-f5a1-d988f3d95fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/23/2021 11:46:54 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "08/23/2021 11:46:54 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=5000,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/runs/Aug23_11-46-54_e20f0214c830,\n",
      "logging_first_step=False,\n",
      "logging_steps=5000,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "output_dir=/content/drive/MyDrive/vn_law/vnlaw-finetune-mlm,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=vnlaw-finetune-mlm,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=None,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/content/drive/MyDrive/vn_law/vnlaw-finetune-mlm,\n",
      "save_on_each_node=False,\n",
      "save_steps=5000,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "08/23/2021 11:46:55 - WARNING - datasets.builder - Using custom data configuration default-e4b4c4f68cbe48ad\n",
      "08/23/2021 11:46:55 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "08/23/2021 11:46:55 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-e4b4c4f68cbe48ad/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5\n",
      "08/23/2021 11:46:55 - WARNING - datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-e4b4c4f68cbe48ad/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
      "08/23/2021 11:46:55 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-e4b4c4f68cbe48ad/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5\n",
      "100% 1/1 [00:00<00:00, 565.42it/s]\n",
      "[INFO|configuration_utils.py:543] 2021-08-23 11:46:55,723 >> loading configuration file /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-285000/config.json\n",
      "[INFO|configuration_utils.py:581] 2021-08-23 11:46:55,724 >> Model config IBertConfig {\n",
      "  \"_name_or_path\": \"NlpHUST/vibert4news-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"force_dequant\": \"none\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"ibert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"quant_mode\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 62000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1664] 2021-08-23 11:46:55,725 >> Didn't find file /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-285000/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1664] 2021-08-23 11:46:55,726 >> Didn't find file /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-285000/tokenizer.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1728] 2021-08-23 11:46:55,727 >> loading file /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-285000/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1728] 2021-08-23 11:46:55,727 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1728] 2021-08-23 11:46:55,727 >> loading file /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-285000/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1728] 2021-08-23 11:46:55,727 >> loading file /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-285000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1728] 2021-08-23 11:46:55,727 >> loading file None\n",
      "[INFO|modeling_utils.py:1273] 2021-08-23 11:46:56,822 >> loading weights file /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-285000/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1520] 2021-08-23 11:47:02,489 >> All model checkpoint weights were used when initializing BertForMaskedLM.\n",
      "\n",
      "[INFO|modeling_utils.py:1529] 2021-08-23 11:47:02,489 >> All the weights of BertForMaskedLM were initialized from the model checkpoint at /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-285000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
      "Running tokenizer on dataset line_by_line:   0% 0/1 [00:00<?, ?ba/s]08/23/2021 11:47:03 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-e4b4c4f68cbe48ad/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-4b0627b5f1587708.arrow\n",
      "Running tokenizer on dataset line_by_line: 100% 1/1 [00:00<00:00,  1.55ba/s]\n",
      "08/23/2021 11:47:06 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:521] 2021-08-23 11:47:06,190 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: special_tokens_mask.\n",
      "[INFO|trainer.py:2167] 2021-08-23 11:47:06,192 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2169] 2021-08-23 11:47:06,192 >>   Num examples = 1000\n",
      "[INFO|trainer.py:2172] 2021-08-23 11:47:06,193 >>   Batch size = 8\n",
      "100% 125/125 [00:05<00:00, 23.21it/s]\n",
      "***** eval metrics *****\n",
      "  eval_loss               =      0.799\n",
      "  eval_runtime            = 0:00:05.39\n",
      "  eval_samples            =       1000\n",
      "  eval_samples_per_second =    185.343\n",
      "  eval_steps_per_second   =     23.168\n",
      "  perplexity              =     2.2232\n"
     ]
    }
   ],
   "source": [
    "!python3 run_mlm.py \\\n",
    "    --model_name_or_path /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/checkpoint-285000 \\\n",
    "    --validation_file /content/drive/MyDrive/vn_law/law.vi.small.txt \\\n",
    "    --do_eval \\\n",
    "    --line_by_line \\\n",
    "    --per_device_train_batch_size 8 \\\n",
    "    --per_device_eval_batch_size 8 \\\n",
    "    --max_seq_length 512 \\\n",
    "    --logging_steps=5000 \\\n",
    "    --save_steps=5000 \\\n",
    "    --eval_steps=5000 \\\n",
    "    --evaluation_strategy steps \\\n",
    "    --output_dir /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L2OmYPtKf2ct",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L2OmYPtKf2ct",
    "outputId": "ba09e39b-e658-41bf-f638-03a381e9330b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-0.4.0-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 4.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.9.0+cu102)\n",
      "Collecting datasets>=1.8.0\n",
      "  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n",
      "\u001b[K     |████████████████████████████████| 264 kB 29.0 MB/s \n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 62.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.17.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->-r requirements.txt (line 2)) (3.7.4.3)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.0.15)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (4.62.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.70.12.2)\n",
      "Collecting fsspec>=2021.05.0\n",
      "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 69.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (2.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (21.0)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
      "\u001b[K     |████████████████████████████████| 243 kB 75.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.3.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (1.1.5)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (4.6.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets>=1.8.0->-r requirements.txt (line 3)) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets>=1.8.0->-r requirements.txt (line 3)) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (2.10)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->-r requirements.txt (line 5)) (1.15.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets>=1.8.0->-r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2018.9)\n",
      "Installing collected packages: xxhash, fsspec, sentencepiece, datasets, accelerate\n",
      "Successfully installed accelerate-0.4.0 datasets-1.11.0 fsspec-2021.7.0 sentencepiece-0.1.96 xxhash-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jrGSJ_KirBGG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrGSJ_KirBGG",
    "outputId": "34e36ee0-9be1-4e16-b9f1-3616aab91041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p1TBPo4jzgTW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p1TBPo4jzgTW",
    "outputId": "68103c7e-8cd0-4432-a47d-1d1f072029f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-23 17:25:08.716482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-23 17:25:09.140872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-23 17:25:09.141405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "Upload started and will continue reading any new data as it's added to the logdir.\n",
      "\n",
      "To stop uploading, press Ctrl-C.\n",
      "\n",
      "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/sdGVTRKwTxeq2DwjYeGzmQ/\n",
      "\n",
      "\u001b[1m[2021-08-23T17:25:09]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2021-08-23T17:25:27]\u001b[0m Total uploaded: 896 scalars, 70 tensors (42.7 kB), 0 binary objects\n"
     ]
    }
   ],
   "source": [
    "!tensorboard dev upload --logdir /content/drive/MyDrive/vn_law/vnlaw-finetune-mlm/runs \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baTTzWaYrBfP",
   "metadata": {
    "id": "baTTzWaYrBfP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "VNLAW_task1_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
